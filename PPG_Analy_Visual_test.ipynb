{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd238e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPG Signal Processing and Visualization with Dash (Interactive)\n",
    "\n",
    "import os\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output, State, ctx\n",
    "import plotly.graph_objs as go\n",
    "from scipy import signal\n",
    "from dash.dash_table import DataTable\n",
    "from dash.dash_table.Format import Format, Scheme\n",
    "from plotly.subplots import make_subplots\n",
    "import importlib.util\n",
    "from typing import Iterable, List, Dict, Tuple, Any, Optional\n",
    "import math\n",
    "from hrv.rri import RRi\n",
    "from hrv.classical import time_domain, frequency_domain, non_linear\n",
    "from hrv.filters import quotient, threshold_filter\n",
    "from hrvanalysis.preprocessing import remove_outliers, remove_ectopic_beats, interpolate_nan_values\n",
    "from hrvanalysis import (\n",
    "    get_time_domain_features,\n",
    "    get_geometrical_features,\n",
    "    get_frequency_domain_features,\n",
    "    get_csi_cvi_features,\n",
    "    get_poincare_plot_features,\n",
    "    get_sampen,\n",
    ")\n",
    "from dash import dash_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7480f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sumary\\n\\n17.08.2025\\nupdate loading folder path\\nadd ABoy++\\nadd moving windows algo\\nadd NLMS Adaptive Noise Cancelling\\n\\n24.08.2025\\nupdate figs\\nadjust threshold of moving classes\\nadjust parameters of NLMS\\n\\nMoving class model need to update\\nNLMS problems:\\n    - big error between moving class window and still class window\\n    - too much fake peaks\\n    - maybe have time delay between ppg and imu due to breathing, heart, bleeding effect\\ngive up time domain adaptive noise canceling:   \\n    - complex model\\n    - variable parameters\\n    - denoise the heart peak\\n    - not robust\\n\\n31.08.2025\\nupdate aboy++ with 80% overlapping\\nimplement EMD \\n\\n07.09.2025\\nupdate threshold in z axis of Aboy++, much robust\\nsvm algo\\n- SKlearn svc - RBF\\n- dataset\\n           label & preview, unable incremental learning\\n- feature\\n          Time: mean, std, RMS, IQR, kurtosis, skew (for PPG, AccMag, #GyroMag, #JerkMag).\\n          Frequency (Welch, Hann): bandpowers in 0.1 - 0.5, 0.5 - 3, 3 - 8 Hz (PPG & IMU), \\n                    spectral entropy (0 - 10 Hz), dominant peak (0.3 - 8 Hz).\\n- train / parameters output\\n- implement decition func in pipline\\n\\n14.09.2025\\ncomplete training dataset sampling and labeling\\ntried SVM for motion classify\\n- good for rest\\n- mix walking and sitting/standing\\n------next step ------  \\n# try SVG + LMS for MA removal with 3D acc data\\n#   \\n# Empirical Mode Decomposition (EMD)\\n# more accurate HR by \\n    - updating Aboy++\\n    - cut dirty window \\n\\n# (give up) DWT + deep learning: CNN+LSTM\\n    - unexplainable\\n    - black box\\n\\n# nose canceling by imu frequency domain weighting \\n  IMU frequence domain weighting + manual classify + moving windows \\n    - unable to denoise noise at heart rate frequency\\n  ...\\n  \\n# singular spectrum analysis (SSA) + spectral subtraction technique\\n  ...\\n  \\n  \\n\\nSNR \\nHR error\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"sumary\n",
    "\n",
    "17.08.2025\n",
    "update loading folder path\n",
    "add ABoy++\n",
    "add moving windows algo\n",
    "add NLMS Adaptive Noise Cancelling\n",
    "\n",
    "24.08.2025\n",
    "update figs\n",
    "adjust threshold of moving classes\n",
    "adjust parameters of NLMS\n",
    "\n",
    "Moving class model need to update\n",
    "NLMS problems:\n",
    "    - big error between moving class window and still class window\n",
    "    - too much fake peaks\n",
    "    - maybe have time delay between ppg and imu due to breathing, heart, bleeding effect\n",
    "give up time domain adaptive noise canceling:   \n",
    "    - complex model\n",
    "    - variable parameters\n",
    "    - denoise the heart peak\n",
    "    - not robust\n",
    "\n",
    "31.08.2025\n",
    "update aboy++ with 80% overlapping\n",
    "implement EMD \n",
    "\n",
    "07.09.2025\n",
    "update threshold in z axis of Aboy++, much robust\n",
    "svm algo\n",
    "- SKlearn svc - RBF\n",
    "- dataset\n",
    "           label & preview, unable incremental learning\n",
    "- feature\n",
    "          Time: mean, std, RMS, IQR, kurtosis, skew (for PPG, AccMag, #GyroMag, #JerkMag).\n",
    "          Frequency (Welch, Hann): bandpowers in 0.1 - 0.5, 0.5 - 3, 3 - 8 Hz (PPG & IMU), \n",
    "                    spectral entropy (0 - 10 Hz), dominant peak (0.3 - 8 Hz).\n",
    "- train / parameters output\n",
    "- implement decition func in pipline\n",
    "\n",
    "14.09.2025\n",
    "complete training dataset sampling and labeling\n",
    "tried SVM for motion classify\n",
    "- good for rest\n",
    "- mix walking and sitting/standing\n",
    "------next step ------  \n",
    "# try SVG + LMS for MA removal with 3D acc data\n",
    "#   \n",
    "# Empirical Mode Decomposition (EMD)\n",
    "# more accurate HR by \n",
    "    - updating Aboy++\n",
    "    - cut dirty window \n",
    "\n",
    "# (give up) DWT + deep learning: CNN+LSTM\n",
    "    - unexplainable\n",
    "    - black box\n",
    "\n",
    "# nose canceling by imu frequency domain weighting \n",
    "  IMU frequence domain weighting + manual classify + moving windows \n",
    "    - unable to denoise noise at heart rate frequency\n",
    "  ...\n",
    "  \n",
    "# singular spectrum analysis (SSA) + spectral subtraction technique\n",
    "  ...\n",
    "  \n",
    "  \n",
    "\n",
    "SNR \n",
    "HR error\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8b130fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "envi = 1\n",
    "\n",
    "windows_address_1 = [\"/mnt/d/Tubcloud/Shared/PPG/Test Data\",\n",
    "                   \"/mnt/d/Tubcloud/Shared/PPG/Test Data/25July25\"]\n",
    "\n",
    "ubuntu_address_0 = [\"/home/trinker/only_view/Test Data\", \n",
    "                  \"/home/trinker/only_view/Test Data/25July25\"]\n",
    "\n",
    "\n",
    "if envi:\n",
    "    DEFAULT_FOLDER_MAIN = windows_address_1[0]\n",
    "    DEFAULT_FOLDER = windows_address_1[1]\n",
    "else:\n",
    "    DEFAULT_FOLDER_MAIN = ubuntu_address_0[0]\n",
    "    DEFAULT_FOLDER = ubuntu_address_0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9232d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "FS = 400  # Sampling frequency in Hz\n",
    "MIN_BPM = 40  # Minimum expected heart rate for artifact rejection\n",
    "MAX_BPM = 180  # Maximum expected heart rate for artifact rejection\n",
    "#DEFAULT_FOLDER_MAIN = \"/mnt/d/Tubcloud/Shared/PPG/Test Data\"\n",
    "#DEFAULT_FOLDER = \"/mnt/d/Tubcloud/Shared/PPG/Test Data/25July25\"\n",
    "#DEFAULT_FOLDER_MAIN = \"/home/trinker/only_view/Test Data\"\n",
    "#DEFAULT_FOLDER = \"/home/trinker/only_view/Test Data/25July25\"\n",
    "PORT: int = 8050                         # Dash port (auto‑open in browser)\n",
    "G = 9.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7193c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Signal Processing Functions ---\n",
    "def highpass_filter(sig, cutoff=0.5, fs=FS, order=2):\n",
    "    \"\"\"Apply high-pass Butterworth filter to remove baseline drift.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = signal.butter(order, cutoff / nyq, btype='high')\n",
    "    return signal.filtfilt(b, a, sig)\n",
    "\n",
    "def bandpass_filter(sig, lowcut=0.5, highcut=5, fs=FS, order=5):\n",
    "    \"\"\"Apply band-pass Butterworth filter to isolate the heart rate frequency range.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = signal.butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return signal.filtfilt(b, a, sig)\n",
    "\n",
    "def notch_filter(sig, notch_freq=50.0, fs=FS, Q=30):\n",
    "    \"\"\"Apply notch filter to remove power line interference (e.g., 50 or 60 Hz).\"\"\"\n",
    "    b, a = signal.iirnotch(notch_freq, Q, fs)\n",
    "    return signal.filtfilt(b, a, sig)\n",
    "\n",
    "def wavelet_denoise(sig, level=4):\n",
    "    \"\"\"Approximate wavelet-like denoising using Savitzky-Golay filtering from scipy.\"\"\"\n",
    "    window_length = min(len(sig) // (2 ** level) * 2 + 1, len(sig))\n",
    "    if window_length < 5:  # ensure minimum window size\n",
    "        window_length = 5 if len(sig) >= 5 else len(sig) | 1\n",
    "    return signal.savgol_filter(sig, window_length, polyorder=3)\n",
    "\n",
    "def robust_std(x):\n",
    "    x = np.asarray(x).ravel()\n",
    "    med = np.median(x)\n",
    "    mad = np.median(np.abs(x - med)) + 1e-12\n",
    "    return 1.4826 * mad\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94a6a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------HR & Peaks---------------------------\n",
    "def estimate_hr(peaks, fs=FS):\n",
    "    \"\"\"Estimate heart rate from detected peak indices.\"\"\"\n",
    "    if len(peaks) < 2:\n",
    "        return np.nan, []\n",
    "    rr = np.diff(peaks) / fs\n",
    "    return 60 / np.mean(rr), rr\n",
    "\n",
    "def detect_common_peaks(ir, red, max_bpm=MAX_BPM):\n",
    "    \"\"\"Detect peaks that are present in both IR and RED signals (intersection).\"\"\"\n",
    "    peaks_ir, _ = signal.find_peaks(ir, distance=int(FS*60/max_bpm), prominence=0.5)\n",
    "    peaks_red, _ = signal.find_peaks(red, distance=int(FS*60/max_bpm), prominence=0.5)\n",
    "    return peaks_ir #only use Ir\n",
    "    #return np.intersect1d(peaks_ir, peaks_red)\n",
    "\n",
    "# --- Artifact Rejection ---\n",
    "def reject_artifacts(peaks, rr_intervals, lower_bpm=MIN_BPM, upper_bpm=MAX_BPM):\n",
    "    \"\"\"Filter out physiologically implausible peaks based on RR interval range.\"\"\"\n",
    "    lower_rr = 60 / upper_bpm\n",
    "    upper_rr = 60 / lower_bpm\n",
    "    valid_indices = np.where((rr_intervals >= lower_rr) & (rr_intervals <= upper_rr))[0]\n",
    "    clean_peaks = [peaks[0]]\n",
    "    for i in valid_indices + 1:\n",
    "        clean_peaks.append(peaks[i])\n",
    "    return np.array(clean_peaks)\n",
    "\n",
    "def caculate_clean_peaks(peaks, fs=FS):\n",
    "    \"\"\"clean hr, clean rr, clean peaks\"\"\"\n",
    "    hr, rr = estimate_hr(peaks, fs)\n",
    "    if np.isnan(hr):\n",
    "        print(f\"⚠️ Could not estimate HR\")\n",
    "        return None\n",
    "\n",
    "    clean_peaks = reject_artifacts(peaks, rr)\n",
    "    if len(clean_peaks) < 2:\n",
    "        print(f\"⚠️ Not enough clean peaks after artifact rejection\")\n",
    "        return None\n",
    "    hr_clean, clean_rr = estimate_hr(clean_peaks, fs)\n",
    "    return hr_clean, clean_rr, clean_peaks\n",
    "\n",
    "#------------hrv----------------\n",
    "def calculate_hrv(rr):\n",
    "    \"\"\"Calculate heart rate variability as the standard deviation of RR intervals (SDNN).\"\"\"\n",
    "    return np.std(rr) * 1000 if len(rr) >= 2 else np.nan\n",
    "\n",
    "# ---------------------- Aboy++ peak detector (raw PPG) ----------------------\n",
    "# —— Windowing utilities ——\n",
    "def window_indices(N, fs, win_sec=1.0, hop_sec=0.5):\n",
    "    w = int(win_sec * fs)\n",
    "    h = int(hop_sec * fs)\n",
    "    w = max(2, w); h = max(1, h)\n",
    "    starts = np.arange(0, max(1, N-w+1), h, dtype=int)\n",
    "    for s in starts:\n",
    "        e = min(N, s + w)\n",
    "        yield s, e\n",
    "        \n",
    "def _detect_maxima_adaptive(sig, fs, min_dist, amp_percentile=65, prom_scale=0.25):\n",
    "    \"\"\"DetectMaxima helper with percentile-based amplitude & prominence.\n",
    "    1) pre-detect peaks loosely; 2) derive thresholds from percentile; 3) final detect.\n",
    "    Returns indices and dict props.\n",
    "    \"\"\"\n",
    "    pre_peaks, _ = signal.find_peaks(sig, distance=max(1, int(min_dist*0.8)))\n",
    "    if len(pre_peaks) == 0:\n",
    "        return np.array([], dtype=int), {}\n",
    "    pk_vals = sig[pre_peaks]\n",
    "    amp_thr = np.percentile(pk_vals, amp_percentile)\n",
    "    prom_thr = max(1e-6, prom_scale * amp_thr)\n",
    "    peaks, props = signal.find_peaks(sig, distance=int(min_dist), prominence=prom_thr)#, height=amp_thr*0.5)\n",
    "    return peaks, props\n",
    "# cacu minmum amp, one peak between 2 -peaks\n",
    "def aboypp_peak_hr(ppg_raw, fs=FS, window_sec=10.0,\n",
    "                    hp_cut=0.2, notch_hz=None,\n",
    "                    init_HRi=0.0, amp_percentile=65,\n",
    "                    low_cut=0.5, hi_cap=8.0,\n",
    "                    min_bpm=MIN_BPM, max_bpm=MAX_BPM):\n",
    "    \"\"\"Aboy++ style windowed peak detector on (minimally-preprocessed) raw PPG.\n",
    "    Steps per 10s window:\n",
    "      • high-pass + optional notch; band-pass with dynamic upper cutoff set by previous HRi\n",
    "      • DetectMaxima → preliminary peaks → PP-times t_pp; define Pd = t_pp above 30th percentile\n",
    "      • HR index: if median(Pd)*0.5 < mean(Pd) < median(Pd)*1.5, HRi = std(Pd)/mean(Pd)*10 else keep previous\n",
    "      • HRwin = fs / ((1+HRi)*3); Final peaks with distance ≥ 2*HRwin, prominence ≥ 25% avg systolic amp\n",
    "      • Update HRi for next window\n",
    "    Returns dict with: peaks_all, hr_series[(t_mid, hr)], HRi_series, hr_global, hrv_ms, rr\n",
    "    \"\"\"\n",
    "    x = highpass_filter(ppg_raw, hp_cut, fs)\n",
    "    if notch_hz:\n",
    "        x = notch_filter(x, f0=notch_hz, fs=fs)\n",
    "    N = len(x)\n",
    "    W = int(window_sec * fs)\n",
    "    peaks_all = []\n",
    "    HRi = float(init_HRi)\n",
    "    hr_series = []\n",
    "    HRi_series = []\n",
    "\n",
    "    for s, e in window_indices(N, fs, window_sec, window_sec):  # non-overlap\n",
    "        seg = x[s:e]\n",
    "        if len(seg) < max(64, int(0.5*fs)):\n",
    "            continue\n",
    "        # dynamic highcut from previous HRi (capped)\n",
    "        high_cut = min(hi_cap, max(1.5, (1.0 + HRi) * 3.0))  # base=3Hz, scaled by (1+HRi)\n",
    "        seg_f = bandpass_filter(seg, low_cut, high_cut, fs=fs, order=2)\n",
    "\n",
    "        # preliminary detection for HR index\n",
    "        dist0 = int(fs * 60 / max_bpm)\n",
    "        pk0, _ = _detect_maxima_adaptive(seg_f, fs, min_dist=dist0, amp_percentile=amp_percentile, prom_scale=0.25)\n",
    "        if len(pk0) >= 2:\n",
    "            tpp = np.diff(pk0) / fs\n",
    "            if len(tpp) > 0:\n",
    "                q30 = np.percentile(tpp, 30)\n",
    "                Pd = tpp[tpp >= q30]\n",
    "                if len(Pd) >= 2:\n",
    "                    m_med, m_mean = np.median(Pd), np.mean(Pd)\n",
    "                    if (m_med*0.5) < m_mean < (m_med*1.5):\n",
    "                        HRi = float(np.std(Pd) / (m_mean + 1e-12) * 10.0)\n",
    "                # else: keep previous HRi\n",
    "\n",
    "        # HR window & final constraint\n",
    "        HRwin = fs / ((1.0 + HRi) * 3.0)\n",
    "        min_dist_final = max(int(2 * HRwin), int(fs * 60 / max_bpm))\n",
    "\n",
    "        # average systolic amplitude from top 30% peaks in seg_f\n",
    "        if len(pk0) > 0:\n",
    "            pk_vals = seg_f[pk0]\n",
    "            top = pk_vals[np.argsort(pk_vals)][int(0.7*len(pk_vals)):] if len(pk_vals) >= 3 else pk_vals\n",
    "            avg_sys = float(np.mean(top)) if len(top) else float(np.mean(pk_vals)) if len(pk_vals) else robust_std(seg_f)\n",
    "        else:\n",
    "            avg_sys = robust_std(seg_f)\n",
    "        prom_final = max(1e-6, 0.25 * avg_sys)\n",
    "\n",
    "        pk_final, _ = signal.find_peaks(seg_f, distance=min_dist_final, prominence=prom_final)\n",
    "        # window HR for plot\n",
    "        if len(pk_final) >= 2:\n",
    "            hr_w, _ = estimate_hr(pk_final + s, fs)\n",
    "            hr_series.append(( (s+e)/(2*fs), hr_w ))\n",
    "        HRi_series.append(( (s+e)/(2*fs), HRi ))\n",
    "\n",
    "        peaks_all.extend(list(pk_final + s))\n",
    "\n",
    "    peaks_all = np.asarray(peaks_all, dtype=int)\n",
    "    # global HR from all peaks with artifact rejection\n",
    "    if len(peaks_all) >= 2:\n",
    "        hr0, rr0 = estimate_hr(peaks_all, fs)\n",
    "        peaks_clean = reject_artifacts(peaks_all, rr0, fs)\n",
    "        if len(peaks_clean) >= 2:\n",
    "            hr_g, rr = estimate_hr(peaks_clean, fs)\n",
    "            hrv_ms = calculate_hrv(rr)\n",
    "        else:\n",
    "            hr_g, rr, hrv_ms = hr0, rr0, calculate_hrv(rr0)\n",
    "    else:\n",
    "        hr_g, rr, hrv_ms = np.nan, [], np.nan\n",
    "\n",
    "    return dict(peaks_all=peaks_all,\n",
    "                hr_series=np.asarray(hr_series) if len(hr_series) else np.empty((0,2)),\n",
    "                HRi_series=np.asarray(HRi_series) if len(HRi_series) else np.empty((0,2)),\n",
    "                hr_global=hr_g, hrv_ms=hrv_ms, rr=rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e3b16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  distance, remove dirty segments, add peaks at boundary of windows\n",
    "\n",
    "def aboypp_peak_hr_windowed(\n",
    "    ppg_raw, fs=400,\n",
    "    window_sec=10.0, hop_sec=2.0,\n",
    "    commit_tail_sec=4.0,           # ← 改成 4 s 提交带\n",
    "    init_HRi=0.0, ema_alpha=0.3,\n",
    "    dedup=True, dedup_coef=0.2,    # 合并后最小RR去重系数（0.5×RR_est）\n",
    "    **aboy_kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Overlapped Aboy++ wrapper:\n",
    "      - 10 s window, 2 s hop (80% overlap) by default\n",
    "      - per-window run of your aboypp_peak_hr(...)\n",
    "      - commit tail 'commit_tail_sec' from each window (e.g., 4 s), then global de-dup\n",
    "      - output per-window HR, HRi, HRwin (samples), and global peaks\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: {\n",
    "      t_mid: (W,)                 # window mid-time (s)\n",
    "      hr_win: (W,)                # HR per window (BPM, NaN allowed)\n",
    "      HRi_win: (W,)               # HRi per window (dimensionless)\n",
    "      HRwin_samp: (W,)            # HRwin per window (in samples)\n",
    "      minRR_sec: (W,)             # 2*HRwin / fs (seconds) - dynamic minimal RR line\n",
    "      peaks_global: (P,)          # committed global peaks (deduped)\n",
    "      per_win_range: list[(s,e)]  # sample range per window\n",
    "      per_win_commit: list[(c0,c1)] # local commit range per window (samples)\n",
    "    }\n",
    "    \"\"\"\n",
    "    x = np.asarray(ppg_raw, float).ravel()\n",
    "    N = len(x)\n",
    "    W = int(window_sec * fs)\n",
    "    H = int(hop_sec * fs)\n",
    "    assert W > H > 0, \"window must be larger than hop\"\n",
    "    tail = int(commit_tail_sec * fs)\n",
    "    tail = max(1, min(tail, W))   # clamp\n",
    "\n",
    "    t_mid, hr_win, HRi_win = [], [], []\n",
    "    HRwin_samp, minRR_sec = [], []\n",
    "    per_win_range, per_win_commit = [], []\n",
    "    peaks_all = []\n",
    "\n",
    "    HRi_prev = float(init_HRi)\n",
    "\n",
    "    for s in range(0, max(1, N - W + 1), H):\n",
    "        e = s + W\n",
    "        seg = x[s:e]\n",
    "\n",
    "        # 你的主算法 (要求 aboypp_peak_hr 返回 peaks_all / hr_global / HRi 或 rr)\n",
    "        info = aboypp_peak_hr(seg, fs=fs, window_sec=window_sec,\n",
    "                              init_HRi=HRi_prev, **aboy_kwargs)\n",
    "\n",
    "        pk_loc = np.asarray(info.get(\"peaks_all\", []), dtype=int)\n",
    "\n",
    "        # HR per window\n",
    "        hr_meas = float(info.get(\"hr_global\", np.nan))\n",
    "        if not np.isfinite(hr_meas):\n",
    "            rr = info.get(\"rr\", None)\n",
    "            if rr is not None and len(rr):\n",
    "                hr_meas = 60.0 / np.median(rr)\n",
    "\n",
    "        # HRi per window（若主算法没返回HRi，这里可能为 NaN）\n",
    "        HRi = float(info.get(\"HRi\", np.nan))\n",
    "\n",
    "        # HRwin（samples），以及 2×HRwin -> 秒\n",
    "        if np.isfinite(HRi):\n",
    "            hrwin = fs / ((1.0 + HRi) * 3.0)\n",
    "            min_rr_s = (2.0 * hrwin) / fs\n",
    "        else:\n",
    "            hrwin = np.nan\n",
    "            min_rr_s = np.nan\n",
    "\n",
    "        # 传递 HRi → 下一窗（EMA）\n",
    "        if np.isfinite(hr_meas):\n",
    "            HRi_prev = (1 - ema_alpha) * HRi_prev + ema_alpha * hr_meas if HRi_prev > 0 else hr_meas\n",
    "\n",
    "        # 记录 per-window 信息\n",
    "        t_mid.append((s + e) / (2.0 * fs))\n",
    "        hr_win.append(hr_meas)\n",
    "        HRi_win.append(HRi)\n",
    "        HRwin_samp.append(hrwin)\n",
    "        minRR_sec.append(min_rr_s)\n",
    "        per_win_range.append((s, e))\n",
    "\n",
    "        # 提交 tail 4 s: [W - tail, W)\n",
    "        c0, c1 = W - tail, W\n",
    "        per_win_commit.append((c0, c1))\n",
    "        if len(pk_loc):\n",
    "            m = (pk_loc >= c0) & (pk_loc < c1)\n",
    "            if np.any(m):\n",
    "                peaks_all.extend((pk_loc[m] + s).tolist())\n",
    "\n",
    "    # 合并输出数组\n",
    "    t_mid   = np.asarray(t_mid, float)\n",
    "    hr_win  = np.asarray(hr_win, float)\n",
    "    HRi_win = np.asarray(HRi_win, float)\n",
    "    HRwin_samp = np.asarray(HRwin_samp, float)\n",
    "    minRR_sec  = np.asarray(minRR_sec, float)\n",
    "\n",
    "    peaks_global = np.asarray(sorted(peaks_all), dtype=int)\n",
    "\n",
    "    # 合并后去重（基于全局 HR 中位数）\n",
    "    if dedup and len(peaks_global) > 1:\n",
    "        valid_hr = hr_win[np.isfinite(hr_win)]\n",
    "        hr_hat = float(np.median(valid_hr)) if len(valid_hr) else 75.0\n",
    "        min_dist = int(dedup_coef * fs * 60.0 / np.clip(hr_hat, 40, 220))  # 0.5×RR_est\n",
    "        keep = [peaks_global[0]]\n",
    "        for p in peaks_global[1:]:\n",
    "            if p - keep[-1] >= min_dist:\n",
    "                keep.append(p)\n",
    "        peaks_global = np.asarray(keep, int)\n",
    "\n",
    "    return dict(\n",
    "        t_mid=t_mid, hr_win=hr_win,\n",
    "        HRi_win=HRi_win, HRwin_samp=HRwin_samp, minRR_sec=minRR_sec,\n",
    "        peaks_global=peaks_global,\n",
    "        per_win_range=per_win_range, per_win_commit=per_win_commit\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def build_aboypp_windowed_sync_figure(\n",
    "    ppg_raw, fs, win_out,\n",
    "    window_sec=10.0, hop_sec=2.0,\n",
    "    height=880, show_commit_band=True, show_hr_points=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Three-row synchronized figure (for Dash):\n",
    "      Row 1: PPG waveform + shaded commit bands + committed peaks\n",
    "      Row 2: HR per window (t_mid vs hr_win)\n",
    "      Row 3: HRi(t) (left y-axis) and 2×HRwin minimal RR (seconds, right y-axis)\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    ppg_raw : 1D array\n",
    "    fs : float\n",
    "    win_out : dict from aboypp_peak_hr_windowed(...)\n",
    "      - 't_mid', 'hr_win', 'HRi_win', 'HRwin_samp', 'minRR_sec'\n",
    "      - 'peaks_global', 'per_win_range', 'per_win_commit'\n",
    "    \"\"\"\n",
    "    x = np.asarray(ppg_raw, float).ravel()\n",
    "    t = np.arange(len(x)) / float(fs)\n",
    "\n",
    "    t_mid   = np.asarray(win_out.get(\"t_mid\", []), float)\n",
    "    hr_win  = np.asarray(win_out.get(\"hr_win\", []), float)\n",
    "    HRi_win = np.asarray(win_out.get(\"HRi_win\", []), float)\n",
    "    minRR_s = np.asarray(win_out.get(\"minRR_sec\", []), float)\n",
    "    peaks_g = np.asarray(win_out.get(\"peaks_global\", []), int)\n",
    "    win_rng = win_out.get(\"per_win_range\", [])\n",
    "    win_cmt = win_out.get(\"per_win_commit\", [])\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1, shared_xaxes=True,\n",
    "        row_heights=[0.5, 0.25, 0.25], vertical_spacing=0.06,\n",
    "        specs=[[{}],[{}],[{\"secondary_y\": True}]]  # bottom subplot has secondary y\n",
    "    )\n",
    "\n",
    "    # --- Row 1: PPG + commit bands + peaks ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=t, y=x, name=\"PPG (raw/minimal)\",\n",
    "                   line=dict(color=\"purple\", width=1.0)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    if show_commit_band and len(win_rng) == len(win_cmt) and len(win_rng) > 0:\n",
    "        for (s, e), (c0, c1) in zip(win_rng, win_cmt):\n",
    "            t0 = (s + int(c0)) / fs\n",
    "            t1 = (s + int(c1)) / fs\n",
    "            fig.add_vrect(x0=t0, x1=t1, fillcolor=\"orange\", opacity=0.15,\n",
    "                          line_width=0, layer=\"below\", row=1, col=1)\n",
    "        # dummy legend entry\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=[None], y=[None], mode=\"markers\",\n",
    "                       marker=dict(color=\"orange\", size=10),\n",
    "                       name=\"Commit band (tail)\"),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    if peaks_g.size:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=t[peaks_g], y=x[peaks_g], mode=\"markers\",\n",
    "                       marker=dict(color=\"red\", size=6),\n",
    "                       name=\"Committed peaks\"),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    # --- Row 2: HR per window ---\n",
    "    mask_hr = np.isfinite(hr_win)\n",
    "    if np.any(mask_hr):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=t_mid[mask_hr], y=hr_win[mask_hr],\n",
    "                mode=\"lines+markers\" if show_hr_points else \"lines\",\n",
    "                line=dict(width=2), marker=dict(size=5),\n",
    "                name=\"HR per window (BPM)\"\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "    # --- Row 3: HRi(t) and 2×HRwin minimal RR (seconds) ---\n",
    "    mask_hri = np.isfinite(HRi_win)\n",
    "    if np.any(mask_hri):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=t_mid[mask_hri], y=HRi_win[mask_hri],\n",
    "                       mode=\"lines+markers\",\n",
    "                       line=dict(color=\"#1f77b4\", width=2),\n",
    "                       marker=dict(size=5),\n",
    "                       name=\"HRi (dimensionless)\"),\n",
    "            row=3, col=1, secondary_y=False\n",
    "        )\n",
    "    mask_rr = np.isfinite(minRR_s)\n",
    "    if np.any(mask_rr):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=t_mid[mask_rr], y=minRR_s[mask_rr],\n",
    "                       mode=\"lines+markers\",\n",
    "                       line=dict(color=\"#2ca02c\", width=2, dash=\"dash\"),\n",
    "                       marker=dict(size=5),\n",
    "                       name=\"2×HRwin (minimal RR, s)\"),\n",
    "            row=3, col=1, secondary_y=True\n",
    "        )\n",
    "\n",
    "    # --- Axes & layout ---\n",
    "    fig.update_yaxes(title_text=\"Amplitude\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"HR (BPM)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"HRi\", row=3, col=1, secondary_y=False)\n",
    "    fig.update_yaxes(title_text=\"Min RR (s)\", row=3, col=1, secondary_y=True)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Time (s)\", row=3, col=1)\n",
    "\n",
    "    # Aesthetics\n",
    "    fig.update_layout(\n",
    "        title=f\"Aboy++ — window={window_sec}s, hop={hop_sec}s (commit tail={int((win_cmt[0][1]-win_cmt[0][0])/fs) if win_cmt else 0}s)\",\n",
    "        height=height,\n",
    "        margin=dict(l=50, r=30, t=50, b=40),\n",
    "        paper_bgcolor=\"white\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0)\n",
    "    )\n",
    "    fig.update_xaxes(showgrid=True, gridcolor=\"rgba(0,0,0,0.08)\")\n",
    "    fig.update_yaxes(showgrid=True, gridcolor=\"rgba(0,0,0,0.08)\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee8caf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Spo2---------------\n",
    "def compute_mean_R(ir, red, peaks, fs=FS):\n",
    "    \"\"\"Return mean R after PI + outlier filtering; NaN if none valid. For Spo2\"\"\"\n",
    "    Rs = []\n",
    "    for p0, p1 in zip(peaks[:-1], peaks[1:]):\n",
    "        seg_ir, seg_red = ir[p0:p1], red[p0:p1]\n",
    "        if seg_ir.size < (fs/5):\n",
    "            continue\n",
    "        ac_ir,  dc_ir  = np.ptp(seg_ir),  np.mean(seg_ir)\n",
    "        ac_red, dc_red = np.ptp(seg_red), np.mean(seg_red)\n",
    "        PI = ac_ir / dc_ir\n",
    "        if PI < 0.02:               # perfusion too weak\n",
    "            continue\n",
    "        R = (ac_red/dc_red) / (ac_ir/dc_ir)\n",
    "        Rs.append(R)\n",
    "    if not Rs:\n",
    "        print(\"None Ratio\")\n",
    "        return np.nan\n",
    "    R_arr = np.asarray(Rs)\n",
    "    print(\"Ratio_raw:\", max(R_arr), min(R_arr), len(R_arr))\n",
    "    med = np.median(R_arr)\n",
    "    mad = np.median(np.abs(R_arr-med))\n",
    "    good = R_arr[np.abs(R_arr-med) <= 3*mad] if mad else R_arr\n",
    "    print(\"Ratio_filtered\", max(good),min(good), len(good))\n",
    "    print(\"R_mean:\", R_arr.mean())\n",
    "    print(\"R_clean_mean:\", good.mean())\n",
    "    return good.mean()\n",
    "\n",
    "# old spo2 algo\n",
    "def estimate_spo2_old(ir, red):\n",
    "    ir_ac = np.ptp(ir)           \n",
    "    ir_dc = np.mean(ir)          \n",
    "    red_ac = np.ptp(red)\n",
    "    red_dc = np.mean(red)\n",
    "    ratio = (red_ac / red_dc) / (ir_ac / ir_dc)  \n",
    "    print(\"ratio_old\", ratio)\n",
    "    return 110 - 25 * ratio   \n",
    "\n",
    "def f_R_poly(R):\n",
    "    \"\"\"linear regression and parameters for SpO2\"\"\"\n",
    "    c0, c1, c2 = 110.0, -25.0, 0 # need regression\n",
    "    return c0 + c1*R + c2*(R**2) \n",
    "\n",
    "def estimate_spo2(ir, red, clean_peaks, fs=FS):\n",
    "    \"\"\"Estimate SpO₂ based on AC/DC ratio of red and infrared signals.\"\"\"\n",
    "    R_bar = compute_mean_R(ir, red, clean_peaks, fs)\n",
    "    return np.nan if np.isnan(R_bar) else f_R_poly(R_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "080f33b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- IMU FEATURES + MOVING-WINDOW CLASSIFIER -------------\n",
    "\n",
    "MOTION_LABELS = [\"Static\", \"StandUp\", \"SitDown\", \"Walking\", \"Resting\", \"Transition\"]\n",
    "LABEL_TO_ID = {name:i for i,name in enumerate(MOTION_LABELS)}\n",
    "LABEL_COLORS = {\n",
    "    \"Static\": \"#141313\",\n",
    "    \"Resting\": \"#4CAF50\",\n",
    "    \"Walking\": \"#2196F3\",\n",
    "    \"StandUp\": \"#FF9800\",\n",
    "    \"SitDown\": \"#E91E63\",\n",
    "    \"Transition\": \"#BDBDBD\",\n",
    "}\n",
    "#--------basic----------\n",
    "def imu_features(acc, gyro, fs):\n",
    "    \"\"\"\n",
    "    input:acc, gyro (N,3)\n",
    "    output:\n",
    "      acc_mag   : √(ax²+ay²+az²)\n",
    "      gyro_mag  : √(gx²+gy²+gz²)\n",
    "      jerk_mag  : |d(acc)/dt|\n",
    "    \"\"\"\n",
    "    acc_mag  = np.linalg.norm(acc,  axis=1)\n",
    "    gyro_mag = np.linalg.norm(gyro, axis=1)\n",
    "    \n",
    "    # jerk \n",
    "    jerk     = np.diff(acc, axis=0, prepend=acc[:1]) * fs\n",
    "    jerk_mag = np.linalg.norm(jerk, axis=1)\n",
    "    return acc_mag, gyro_mag, jerk_mag\n",
    "\n",
    "\n",
    "def imu_bandpass_filter(sig, lowcut=0.1, highcut=520, fs=FS, order=5):\n",
    "    \"\"\"Apply band-pass Butterworth filter to isolate the heart rate frequency range.\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = signal.butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return signal.filtfilt(b, a, sig, axis=0)\n",
    "\n",
    "def butter_filt(sig, Wn, btype, order=4, axis=0):\n",
    "    \"\"\"Butterworth + filtfilt (zero-phase). Wn: normalized or [low, high].\"\"\"\n",
    "    b, a = signal.butter(order, Wn, btype=btype)\n",
    "    return signal.filtfilt(b, a, sig, axis=axis)\n",
    "\n",
    "def lp(sig, fc, fs=FS, order=4, axis=0):\n",
    "    return butter_filt(sig, fc/(0.5*fs), 'low', order=order, axis=axis)\n",
    "\n",
    "def hp(sig, fc, fs=FS, order=2, axis=0):\n",
    "    return butter_filt(sig, fc/(0.5*fs), 'high', order=order, axis=axis)\n",
    "\n",
    "def notch(sig, f0=50.0, Q=30.0, fs=FS, axis=0):\n",
    "    b, a = signal.iirnotch(f0, Q, fs)\n",
    "    return signal.filtfilt(b, a, sig, axis=axis)\n",
    "\n",
    "def preprocess_ppg_min(ppg, fs=FS, hp_cut=0.2, mains=None):\n",
    "    \"\"\"\n",
    "    - Remove DC / drift (high-pass 0.1-0.3 Hz; default 0.2 Hz)\n",
    "    - Optional mains notch at 50/60 Hz\n",
    "    - Do NOT narrow band-pass yet (keep info for ANC / spectral methods)\n",
    "    \"\"\"\n",
    "    y = hp(ppg, hp_cut, fs=fs, order=2, axis=0)\n",
    "    if mains in (50, 60):\n",
    "        y = notch(y, f0=float(mains), Q=30.0, fs=fs, axis=0)\n",
    "    return y\n",
    "\n",
    "def robust_mean(x, axis=0):\n",
    "    \"\"\"Median + MAD \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    med = np.median(x, axis=axis, keepdims=True)\n",
    "    mad = np.median(np.abs(x - med), axis=axis, keepdims=True) + 1e-12\n",
    "    z = np.abs(x - med) / mad\n",
    "    mask = (z < 3.5)  # Tukey-like rule\n",
    "    \n",
    "    if axis == 0:\n",
    "        val = []\n",
    "        for j in range(x.shape[1]):\n",
    "            col = x[:, j]\n",
    "            msk = mask[:, j]\n",
    "            val.append(col[msk].mean() if msk.any() else col.mean())\n",
    "        return np.array(val)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def acc_to_rp_from_mean(acc_mean):\n",
    "    \"\"\"roll/pitch by acc\"\"\"\n",
    "    ax, ay, az = acc_mean\n",
    "    roll  = np.arctan2( ay,  np.sqrt(ax**2 + az**2) )\n",
    "    pitch = np.arctan2(-ax,  np.sqrt(ay**2 + az**2) )\n",
    "    return roll, pitch\n",
    "\n",
    "def gravity_body_from_rp(roll, pitch):\n",
    "    R_x = np.array([[1,0,0],\n",
    "                    [0, np.cos(roll), -np.sin(roll)],\n",
    "                    [0, np.sin(roll),  np.cos(roll)]])\n",
    "    R_y = np.array([[ np.cos(pitch),0,np.sin(pitch)],\n",
    "                    [0,1,0],\n",
    "                    [-np.sin(pitch),0,np.cos(pitch)]])\n",
    "    R = R_x @ R_y\n",
    "    return R.T @ np.array([0,0,G])  # g in body frame\n",
    "\n",
    "\n",
    "# —— Simple LPF gravity path (fast fallback) ——\n",
    "def estimate_gravity_lpf(acc_mps2, fs=FS, fc=0.3):\n",
    "    g_vec = lp(acc_mps2, fc, fs)\n",
    "    a_dyn = acc_mps2 - g_vec\n",
    "    g_dir = g_vec / (np.linalg.norm(g_vec, axis=1, keepdims=True) + 1e-9)\n",
    "    return g_vec, a_dyn, g_dir\n",
    "\n",
    "# —— Spectral helper ——\n",
    "def _welch_peak(freqs, Pxx, f_lo=0.8, f_hi=3.0):\n",
    "    mask = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    if not np.any(mask):\n",
    "        return np.nan, 0.0\n",
    "    f_band, P_band = freqs[mask], Pxx[mask]\n",
    "    i = int(np.argmax(P_band))\n",
    "    fpk, ppk = float(f_band[i]), float(P_band[i])\n",
    "    snr = ppk / (np.median(P_band) + 1e-12)\n",
    "    return fpk, snr\n",
    "\n",
    "#---------bias-----------\n",
    "def estimate_bias_from_static(df, idx_start=int(5*FS), idx_end=int(100*FS), fs=FS,\n",
    "                              acc_lp_fc=20, gyro_lp_fc=40,\n",
    "                              index = True,\n",
    "                              acc_in_g=True, gyro_in_dps=True):\n",
    "    \"\"\"\n",
    "    df: DataFrame including AX,AY,AZ,GX,GY,GZ\n",
    "    idx_start, idx_end: sampling sig [start, end)\n",
    "    acc_in_g: acc unit in g, gyro_in_dps: rotete unit in °/s(dps)\n",
    "    return:\n",
    "      acc_bias (3,), gyro_bias (3,), roll0, pitch0, quality(dict)\n",
    "    \"\"\"\n",
    "    if index:\n",
    "        seg = slice(int(idx_start), int(idx_end))\n",
    "        acc = df[['AX','AY','AZ']].to_numpy(float)[seg]\n",
    "        gyro = df[['GX','GY','GZ']].to_numpy(float)[seg]\n",
    "    else:\n",
    "        acc = df[['AX','AY','AZ']].to_numpy(float)\n",
    "        gyro = df[['GX','GY','GZ']].to_numpy(float)\n",
    "\n",
    "    # transfer unit\n",
    "    if acc_in_g:   acc = acc * G\n",
    "    if gyro_in_dps: gyro = np.deg2rad(gyro)\n",
    "\n",
    "    # lowpass\n",
    "    acc_f  = lp(acc,  acc_lp_fc, fs, order=4, axis=0)\n",
    "    gyro_f = lp(gyro, gyro_lp_fc, fs, order=4, axis=0)\n",
    "\n",
    "    # robust mean\n",
    "    acc_mean  = robust_mean(acc_f,  axis=0)\n",
    "    gyro_mean = robust_mean(gyro_f, axis=0)\n",
    "\n",
    "    # ini attitude by acc mean\n",
    "    roll0, pitch0 = acc_to_rp_from_mean(acc_mean)\n",
    "\n",
    "    #\n",
    "    g_body0 = gravity_body_from_rp(roll0, pitch0)\n",
    "    acc_bias  = acc_mean  - g_body0  # g + bias\n",
    "    gyro_bias = gyro_mean  # gyro bias\n",
    "\n",
    "    # quality check：acc_norm 与 g 的偏差，gyro 均方\n",
    "    acc_residual = np.linalg.norm(acc_mean - acc_bias) - G\n",
    "    gyro_rms = np.sqrt(np.mean(gyro_f**2, axis=0))\n",
    "    quality = dict(\n",
    "        acc_norm_error=float(acc_residual),\n",
    "        gyro_rms=list(gyro_rms),\n",
    "        window_len=int(idx_end-idx_start)\n",
    "    )\n",
    "    return acc_bias, gyro_bias, roll0, pitch0, quality\n",
    "\n",
    "\n",
    "#---------EKF for attitude----------------\n",
    "def ekf_attitude_rp(gyro, acc, fs=FS,\n",
    "                    q_proc = np.array([5.0, 5.0,   # process noise for roll,pitch (bpm-ish scale -> just relative)\n",
    "                                       0.05,0.05,0.05]),  # bias random-walk\n",
    "                    r_meas_base = np.array([0.5, 0.5]),  # accel-derived roll/pitch noise (rad^2)\n",
    "                    alpha_dyn_R = 3.0,\n",
    "                    init=None):\n",
    "    \"\"\"\n",
    "    Extended Kalman Filter over state:\n",
    "        x = [roll, pitch, bgx, bgy, bgz]^T\n",
    "    Process model (discrete Euler):\n",
    "        roll_{k+1}  = roll_k  + dt * roll_dot(roll,pitch, gyro-bias)\n",
    "        pitch_{k+1} = pitch_k + dt * pitch_dot(roll,pitch, gyro-bias)\n",
    "\n",
    "    Measurement:\n",
    "        z = [roll_acc, pitch_acc] from accelerometer\n",
    "\n",
    "    r_meas adaptively upweighted when |acc| deviates from g (i.e., dynamic acceleration)\n",
    "        scale = 1 + alpha_dyn_R * max(0, | |acc|-g | / g)\n",
    "\n",
    "    Returns:\n",
    "      roll, pitch(arrays)\n",
    "    \"\"\"\n",
    "    dt = 1.0/fs\n",
    "    N = len(acc)\n",
    "    roll  = np.zeros(N)\n",
    "    pitch = np.zeros(N)\n",
    "    bg    = np.zeros((N,3))\n",
    "\n",
    "    if init is not None:\n",
    "        roll[0]  = float(init.get('roll0', 0.0))\n",
    "        pitch[0] = float(init.get('pitch0', 0.0))\n",
    "        bg[0]    = np.array(init.get('bg0', [0.0,0.0,0.0]), dtype=float)\n",
    "    else:\n",
    "        ax0, ay0, az0 = acc[0]\n",
    "        roll[0]  = np.arctan2( ay0,  np.sqrt(ax0**2 + az0**2) )\n",
    "        pitch[0] = np.arctan2(-ax0,  np.sqrt(ay0**2 + az0**2) )\n",
    "        bg[0]    = np.zeros(3)\n",
    "\n",
    "    P = np.diag([1.0, 1.0, 0.5,0.5,0.5])\n",
    "    Q = np.diag(q_proc) * dt\n",
    "\n",
    "    for k in range(1, N):\n",
    "        r, p = roll[k-1], pitch[k-1]\n",
    "        gx, gy, gz = gyro[k] - bg[k-1]\n",
    "\n",
    "        roll_dot  = gx + gy*np.sin(r)*np.tan(p) + gz*np.cos(r)*np.tan(p)\n",
    "        pitch_dot = gy*np.cos(r) - gz*np.sin(r)\n",
    "\n",
    "        x_prev = np.array([r, p, *bg[k-1]])\n",
    "        x_pred = x_prev + dt*np.array([roll_dot, pitch_dot, 0.0, 0.0, 0.0])\n",
    "\n",
    "        s, c = np.sin(r), np.cos(r)\n",
    "        tp = np.tan(p); sp2 = 1/np.cos(p)**2\n",
    "\n",
    "        droll_droll  = gy*c*tp - gz*s*tp\n",
    "        droll_dpitch = gy*s*sp2 + gz*c*sp2\n",
    "        droll_dbgx   = -1.0\n",
    "        droll_dbgy   = -s*tp\n",
    "        droll_dbgz   = -c*tp\n",
    "\n",
    "        dpitch_droll = -gy*s - gz*c\n",
    "        dpitch_dpitch= 0.0\n",
    "        dpitch_dbgx  = 0.0\n",
    "        dpitch_dbgy  = -c\n",
    "        dpitch_dbgz  =  s\n",
    "\n",
    "        F = np.array([\n",
    "            [1 + dt*droll_droll,   dt*droll_dpitch,   dt*droll_dbgx, dt*droll_dbgy, dt*droll_dbgz],\n",
    "            [dt*dpitch_droll,      1 + dt*dpitch_dpitch, dt*dpitch_dbgx, dt*dpitch_dbgy, dt*dpitch_dbgz],\n",
    "            [0,0,1,0,0],\n",
    "            [0,0,0,1,0],\n",
    "            [0,0,0,0,1]\n",
    "        ])\n",
    "        P = F @ P @ F.T + Q\n",
    "\n",
    "        ax, ay, az = acc[k]\n",
    "        roll_acc  = np.arctan2( ay,  np.sqrt(ax**2 + az**2) )\n",
    "        pitch_acc = np.arctan2(-ax,  np.sqrt(ay**2 + az**2) )\n",
    "        z = np.array([roll_acc, pitch_acc])\n",
    "\n",
    "        acc_norm = np.linalg.norm(acc[k])\n",
    "        dev = max(0.0, abs(acc_norm - G) / G)\n",
    "        R = np.diag(r_meas_base * (1.0 + alpha_dyn_R * dev))\n",
    "\n",
    "        H = np.array([[1,0,0,0,0],\n",
    "                      [0,1,0,0,0]])\n",
    "        y = z - H @ x_pred\n",
    "        S = H @ P @ H.T + R\n",
    "        K = P @ H.T @ np.linalg.inv(S)\n",
    "\n",
    "        x_upd = x_pred + (K @ y).ravel()\n",
    "        P = (np.eye(5) - K @ H) @ P\n",
    "\n",
    "        roll[k], pitch[k] = x_upd[0], x_upd[1]\n",
    "        bg[k] = x_upd[2:5]\n",
    "\n",
    "    return roll, pitch, bg\n",
    "\n",
    "\n",
    "\n",
    "def gravity_from_rp(roll, pitch):\n",
    "    \"\"\"Gravity (m/s²) time series in body frame from arrays roll/pitch (yaw ignored).\"\"\"\n",
    "    N = len(roll)\n",
    "    g_body = np.zeros((N,3))\n",
    "    for k,(r,p) in enumerate(zip(roll, pitch)):\n",
    "        R_x = np.array([[1,0,0],\n",
    "                        [0, np.cos(r), -np.sin(r)],\n",
    "                        [0, np.sin(r),  np.cos(r)]])\n",
    "        R_y = np.array([[ np.cos(p),0,np.sin(p)],\n",
    "                        [0,1,0],\n",
    "                        [-np.sin(p),0,np.cos(p)]])\n",
    "        R = R_x @ R_y\n",
    "        g_body[k] = R.T @ np.array([0,0,G])\n",
    "    return g_body\n",
    "\n",
    "global THRESHOLD \n",
    "THRESHOLD  =  dict(thr_acc_low=0.8, thr_gyro_low=np.deg2rad(30), thr_jerk_low=2.5, jerk_high=2.0, imp_th=0.6, snr_th=3.0)\n",
    "\n",
    "# ---------------------- Motion classification (LPF or EKF) ------------------\n",
    "def classify_window(a_dyn_win, gyro_win, gdir_win, fs,\n",
    "                     thr_acc_low=0.8, thr_gyro_low=np.deg2rad(10), thr_jerk_low=0.5,\n",
    "                     jerk_high=2.0, imp_th=0.6, snr_th=3.0):\n",
    "    \n",
    "    acc_mag = np.linalg.norm(a_dyn_win, axis=1)\n",
    "    gyro_mag = np.linalg.norm(gyro_win, axis=1)\n",
    "    acc_rms  = float(np.sqrt(np.mean(acc_mag**2)))\n",
    "    gyro_rms = float(np.sqrt(np.mean(gyro_mag**2)))\n",
    "    jerk     = np.diff(a_dyn_win, axis=0, prepend=a_dyn_win[:1]) * fs\n",
    "    jerk_mag = np.linalg.norm(jerk, axis=1)\n",
    "    jerk_rms = float(np.sqrt(np.mean(jerk_mag**2)))\n",
    "    #print(jerk_rms)\n",
    "    f, Pxx = signal.welch(acc_mag, fs=fs, window='hann', nperseg=min(len(acc_mag), int(2*fs)))\n",
    "    fpk, snr = _welch_peak(f, Pxx, 0.8, 3.0)\n",
    "    vproj = np.sum(np.sum(a_dyn_win * gdir_win, axis=1)) / fs\n",
    "    if (gyro_rms < thr_gyro_low) and (acc_rms < thr_acc_low) and (jerk_rms < thr_jerk_low):\n",
    "        return \"Static\"\n",
    "    if (snr > snr_th) and (0.8 <= fpk <= 3.0) and (acc_rms > thr_acc_low):\n",
    "        return \"Walking\"\n",
    "    if (jerk_rms > jerk_high) and (abs(vproj) > imp_th):\n",
    "        return \"StandUp\" if vproj > 0 else \"SitDown\"\n",
    "    return \"Transition\"\n",
    "\n",
    "def promote_resting(labels, times, min_rest_sec=5.0):\n",
    "    out = labels[:]\n",
    "    i = 0\n",
    "    while i < len(labels):\n",
    "        if labels[i] == \"Static\":\n",
    "            j = i\n",
    "            while j+1 < len(labels) and labels[j+1] == \"Static\":\n",
    "                j += 1\n",
    "            dur = times[j][1] - times[i][0]\n",
    "            if dur >= min_rest_sec:\n",
    "                for k in range(i, j+1):\n",
    "                    out[k] = \"Resting\"\n",
    "            i = j + 1\n",
    "        else:\n",
    "            i += 1\n",
    "    return out\n",
    "\n",
    "def samplewise_labels(N, fs, win_list, win_labels):\n",
    "    C = len(MOTION_LABELS)\n",
    "    votes = np.zeros((N, C), dtype=int)\n",
    "    for (s,e), lab in zip(win_list, win_labels):\n",
    "        votes[s:e, LABEL_TO_ID[lab]] += 1\n",
    "    ids = votes.argmax(axis=1)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def imu_preprocess_with_kf(df, cols=None, fs=FS, acc_fc=20, gyro_fc=40,  static_t0=5.0, static_t1=100.0):\n",
    "    \"\"\"\n",
    "    Full IMU preprocessing:\n",
    "      1) initial bias estimation over a static segment\n",
    "      2) bias removal\n",
    "      3) low-pass accel/gyro\n",
    "      4) EKF (roll,pitch + gyro bias)\n",
    "      5) remove gravity → dynamic acceleration a_dyn\n",
    "      6) scalar metrics: AccMag, GyroMag, JerkMag\n",
    "    Returns: dict with arrays and metrics.\n",
    "    \"\"\"\n",
    "    if cols == None:\n",
    "        cols = dict(AX='AX',AY='AY',AZ='AZ',GX='GX',GY='GY',GZ='GZ')\n",
    "        \n",
    "    # Load and convert units\n",
    "    acc_g  = df[[cols['AX'], cols['AY'], cols['AZ']]].to_numpy(float)\n",
    "    gyro_d = df[[cols['GX'], cols['GY'], cols['GZ']]].to_numpy(float)\n",
    "    acc    = acc_g * G\n",
    "    gyro   = np.deg2rad(gyro_d)\n",
    "    \n",
    "    # 1) estimate biases from a static segment [static_t0, static_t1) in seconds\n",
    "    idx0 = int(static_t0 * fs)\n",
    "    idx1 = int(static_t1 * fs)\n",
    "    N = len(acc)\n",
    "    t = N/fs\n",
    "    if t/30 > (idx1-idx0):\n",
    "        acc_b, gyr_b, r0, p0, qual = estimate_bias_from_static(df, idx0, idx1, fs=fs, index=True,\n",
    "                                                            acc_in_g=True, gyro_in_dps=True)\n",
    "    else:\n",
    "        acc_b = 0\n",
    "        gyr_b = 0\n",
    "        r0 = 0\n",
    "        p0 = 0\n",
    "    # 2) bias removal and LPF\n",
    "    \n",
    "    acc_bc = acc - acc_b\n",
    "    gyro_bc= gyro - gyr_b\n",
    "    acc_lp = lp(acc_bc, acc_fc, fs)\n",
    "    gyro_lp= lp(gyro_bc, gyro_fc, fs)\n",
    "    \n",
    "    # 3) EKF attitude  (roll,pitch,gyro bias)\n",
    "    init = dict(roll0=r0, pitch0=p0, bg0=gyr_b)\n",
    "    roll, pitch, bg = ekf_attitude_rp(gyro_lp, acc_lp, fs=fs, init=None) # initial curently use first secs\n",
    "    \n",
    "    # 4) gravity removal\n",
    "    g_body = gravity_from_rp(roll, pitch)\n",
    "    a_dyn  = acc_lp - g_body\n",
    "    g_dir  = g_body / (np.linalg.norm(g_body, axis=1, keepdims=True) + 1e-9)\n",
    "    \n",
    "    # 5) metrics\n",
    "    acc_mag  = np.linalg.norm(a_dyn, axis=1)\n",
    "    gyro_mag = np.linalg.norm((gyro_lp), axis=1)\n",
    "    jerk     = np.diff(a_dyn, axis=0, prepend=a_dyn[:1]) * fs\n",
    "    jerk_mag = np.linalg.norm(jerk, axis=1)\n",
    "    \n",
    "    output = dict(\n",
    "        acc_raw = acc_g,\n",
    "        gyro_raw = gyro_d,\n",
    "        acc = acc,\n",
    "        gyro = gyro,\n",
    "        acc_f=acc_lp, \n",
    "        gyr_f=gyro_lp, \n",
    "        jerk = jerk, \n",
    "        roll=roll, \n",
    "        pitch=pitch, \n",
    "        gyro_bias=bg,\n",
    "        g_body=g_body,\n",
    "        g_dir = g_dir, \n",
    "        a_dyn=a_dyn,\n",
    "        AccMag=acc_mag, \n",
    "        GyroMag=gyro_mag, \n",
    "        JerkMag=jerk_mag\n",
    "    )\n",
    "\n",
    "    return output\n",
    "\n",
    "def classify_motion_from_df(df, fs=FS, cols=None, win_sec=1.0, hop_sec=0.5, thresholds=THRESHOLD,\n",
    "                             use_ekf=True, static_t0=5.0, static_t1=10.0):\n",
    "    \"\"\"Motion classifier with two gravity-removal paths:\n",
    "    - LPF path (default): fast, no static segment required.\n",
    "    - EKF path (optional): uses static segment to estimate sensor biases, then EKF roll/pitch and gravity removal.\n",
    "    \"\"\"\n",
    "    imu_out = imu_preprocess_with_kf(df, cols, fs, static_t0=static_t0, static_t1=static_t1)\n",
    "    acc_g = imu_out['acc_raw']\n",
    "    gyro_d = imu_out['gyro_raw']\n",
    "    acc = imu_out['acc']\n",
    "    gyro = imu_out['gyro']\n",
    "    acc_lp = imu_out['acc_f'] \n",
    "    gyro_lp = imu_out['gyr_f'] \n",
    "    jerk = imu_out['jerk'] \n",
    "    roll=imu_out['roll'] \n",
    "    pitch=imu_out['pitch'] \n",
    "    bg = imu_out['gyro_bias']\n",
    "    g_body=imu_out['g_body']\n",
    "    g_dir = imu_out['g_dir'] \n",
    "    a_dyn= imu_out['a_dyn']\n",
    "    acc_mag = imu_out['AccMag'] \n",
    "    gyro_mag = imu_out['GyroMag'] \n",
    "    jerk_mag = imu_out['JerkMag']\n",
    "    \n",
    "\n",
    "    # Window-wise labels\n",
    "    N = len(acc)\n",
    "    win_list, win_labels, win_times = [], [], []\n",
    "    thr = dict(thr_acc_low=0.4, thr_gyro_low=np.deg2rad(10), thr_jerk_low=0.5, jerk_high=2.0, imp_th=0.6, snr_th=3.0)\n",
    "    if thresholds:\n",
    "        thr.update(thresholds)\n",
    "    for s,e in window_indices(N, fs, win_sec, hop_sec):\n",
    "        lab = classify_window(a_dyn[s:e], (gyro_lp if use_ekf else lp(gyro, 40, fs))[s:e], g_dir[s:e], fs, **thr)\n",
    "        win_list.append((s,e)); win_labels.append(lab); win_times.append((s/fs, e/fs))\n",
    "    win_labels2 = promote_resting(win_labels, win_times, min_rest_sec=5.0)\n",
    "    ids = samplewise_labels(N, fs, win_list, win_labels2)\n",
    "\n",
    "    # Scalars for ANC\n",
    "    acc_mag  = np.linalg.norm(a_dyn, axis=1)\n",
    "    gyro_mag = np.linalg.norm((gyro_lp if use_ekf else lp(gyro, 40, fs)), axis=1)\n",
    "    jerk     = np.diff(a_dyn, axis=0, prepend=a_dyn[:1]) * fs\n",
    "    jerk_mag = np.linalg.norm(jerk, axis=1)\n",
    "    t = df['Time'].values if 'Time' in df.columns else np.arange(N)/fs\n",
    "    unique, counts = np.unique(ids, return_counts=True)\n",
    "    frac = {MOTION_LABELS[i]: float(counts[j]/N) for j,i in enumerate(unique)}\n",
    "    return dict(time=t, a_dyn=a_dyn, acc_mag=acc_mag, gyro_mag=gyro_mag, jerk_mag=jerk_mag,\n",
    "                windows=win_list, labels=win_labels2, ids=ids, frac=frac)\n",
    "# =========================================================\n",
    "# 3) Adaptive Noise Cancellation (ANC) for PPG with IMU refs\n",
    "#    ── Multi-input NLMS (reference = IMU features)\n",
    "# =========================================================\n",
    "def build_xref_from_motion(imu_out):\n",
    "    \"\"\"\n",
    "    Construct the multi-reference matrix Xref for ANC.\n",
    "    Columns: [a_dyn_x, a_dyn_y, a_dyn_z, AccMag, GyroMag, JerkMag]  → shape (N,6)\n",
    "    imu_out: dict returned by imu_preprocess_with_kf(...),\n",
    "             must contain keys: 'a_dyn','AccMag','GyroMag','JerkMag'\n",
    "    \"\"\"\n",
    "    Xref = np.column_stack([\n",
    "        imu_out['a_dyn'][:, 0],           # dynamic accel x (m/s^2)\n",
    "        imu_out['a_dyn'][:, 1],           # dynamic accel y (m/s^2)\n",
    "        imu_out['a_dyn'][:, 2],           # dynamic accel z (m/s^2)\n",
    "        imu_out['acc_mag'],                # ||a_dyn|| (m/s^2)\n",
    "        imu_out['gyro_mag'],               # ||omega|| (rad/s)\n",
    "        imu_out['jerk_mag']                # ||d(a_dyn)/dt|| (m/s^3)\n",
    "    ])\n",
    "    names = [\"a_dyn_x\",\"a_dyn_y\",\"a_dyn_z\",\"AccMag\",\"GyroMag\",\"JerkMag\"]\n",
    "    return Xref, names\n",
    "\n",
    "def standardize_cols(X, eps=1e-8):\n",
    "    \"\"\"Z-score columns to avoid scaling issues for NLMS.\"\"\"\n",
    "    mu = X.mean(axis=0)\n",
    "    sd = X.std(axis=0) + eps\n",
    "    return (X - mu) / sd, mu, sd\n",
    "\n",
    "def motion_mask_from_labels(ids, fs=FS, pad_sec=0.25):\n",
    "    moving_ids = [LABEL_TO_ID[x] for x in (\"Walking\",\"StandUp\",\"SitDown\",\"Transition\")]\n",
    "    mask = np.isin(ids, moving_ids)\n",
    "    pad = int(pad_sec*fs)\n",
    "    if pad > 0 and mask.any():\n",
    "        idx = np.where(mask)[0]\n",
    "        for i in idx:\n",
    "            mask[max(0,i-pad):min(len(mask), i+pad+1)] = True\n",
    "    return mask\n",
    "\n",
    "def nlms_multi(ppg, Xref, mu=0.02, eps=1e-6, win=None, return_weights=True):\n",
    "    \"\"\"\n",
    "    Multi-input NLMS (Normalized LMS).\n",
    "      Prediction:  y_hat[n] = w^T[n] x[n]\n",
    "      Error:       e[n]     = ppg[n] - y_hat[n]\n",
    "      Update:      w[n+1]   = w[n] + mu * e[n] * x[n] / (eps + ||x[n]||^2)   (only if win[n] is True)\n",
    "\n",
    "    Inputs:\n",
    "      ppg  : (N,)        — minimally preprocessed PPG (e.g., DC removed, mains notched)\n",
    "      Xref : (N,M)       — references (IMU-derived), recommend M=6 as defined in build_xref_from_imu\n",
    "      mu   : step size   — 0.01~0.05 (start with 0.02)\n",
    "      win  : (N,) bool   — update gate (e.g., motion window). If None, always update.\n",
    "    Returns:\n",
    "      y_clean : (N,)     — residual (cleaned PPG)\n",
    "      W       : (N,M)    — weight history (for diagnostics), returned iff return_weights=True\n",
    "    \"\"\"\n",
    "    ppg = np.asarray(ppg, float).ravel()\n",
    "    X   = np.asarray(Xref, float)\n",
    "    N, M = X.shape\n",
    "    y_clean = np.zeros(N, dtype=float)\n",
    "    if return_weights:\n",
    "        W = np.zeros((N, M), dtype=float)\n",
    "    w = np.zeros(M, dtype=float)\n",
    "\n",
    "    for n in range(N):\n",
    "        x = X[n]\n",
    "        y_hat = float(np.dot(w, x))\n",
    "        e = ppg[n] - y_hat\n",
    "        # gated adaptation\n",
    "        if win is None or win[n]:\n",
    "            denom = eps + np.dot(x, x)\n",
    "            w += (mu * e * x) / denom\n",
    "        y_clean[n] = e\n",
    "        if return_weights:\n",
    "            W[n] = w\n",
    "\n",
    "    return (y_clean, W) if return_weights else (y_clean, None)\n",
    "\n",
    "# ---------------------- HR from ANC (peak detection on ANC output) ----------\n",
    "\n",
    "def hr_from_anc_pipeline(ppg_raw, imu_res, fs=FS,\n",
    "                         hp_cut=0.2, notch_hz=None,\n",
    "                         anc_mu=0.02, gate_pad=0.25,\n",
    "                         bp_lo=0.5, bp_hi=5.0,\n",
    "                         min_bpm=MIN_BPM, max_bpm=MAX_BPM):\n",
    "    \"\"\"End-to-end HR estimation on ANC-cleaned PPG (non-motion gating).\"\"\"\n",
    "    y_min = highpass_filter(ppg_raw, hp_cut, fs)\n",
    "    if notch_hz:\n",
    "        y_min = notch_filter(y_min, f0=notch_hz, fs=fs)\n",
    "    Xref, _ = build_xref_from_motion(imu_res)\n",
    "    Xz, mu_x, sd_x = standardize_cols(Xref)\n",
    "    gate = motion_mask_from_labels(imu_res['ids'], fs=fs, pad_sec=gate_pad)  # True=Motion\n",
    "    y_clean, W = nlms_multi(y_min, Xz, mu=anc_mu, win=gate, return_weights=True)\n",
    "    y_band = butter_filt(y_clean, [bp_lo/(0.5*fs), bp_hi/(0.5*fs)], 'band', order=2)\n",
    "    dist = int(fs * 60 / max_bpm)\n",
    "    good = ~gate\n",
    "    prom_ref = robust_std(y_band[good]) if np.any(good) else robust_std(y_band)\n",
    "    prom = max(1e-6, 0.5 * prom_ref)\n",
    "    peaks_all, _ = signal.find_peaks(y_band, distance=dist, prominence=prom)\n",
    "    peaks_nm = peaks_all[good[peaks_all]] if np.any(peaks_all) else np.array([], dtype=int)\n",
    "    use_peaks = peaks_nm if len(peaks_nm) >= 2 else peaks_all\n",
    "    hr0, rr0 = estimate_hr(use_peaks, fs)\n",
    "    if np.isnan(hr0) or len(use_peaks) < 2:\n",
    "        return dict(y_min=y_min, y_clean=y_clean, y_band=y_band, gate=gate,\n",
    "                    peaks_all=peaks_all, peaks_nm=peaks_nm, peaks_clean=np.array([], int),\n",
    "                    hr=np.nan, hrv=np.nan, rr=[])\n",
    "    peaks_clean = reject_artifacts(use_peaks, rr0, fs)\n",
    "    if len(peaks_clean) < 2:\n",
    "        peaks_clean = use_peaks\n",
    "    hr, rr = estimate_hr(peaks_clean, fs)\n",
    "    hrv = calculate_hrv(rr)\n",
    "    return dict(y_min=y_min, y_clean=y_clean, y_band=y_band, gate=gate,\n",
    "                peaks_all=peaks_all, peaks_nm=peaks_nm, peaks_clean=peaks_clean,\n",
    "                hr=hr, hrv=hrv, rr=rr)\n",
    "# =========================================================\n",
    "# 4) End-to-end: IMU preprocess + ANC on PPG (single window)\n",
    "# =========================================================\n",
    "    \"\"\"def imu_preprocess_and_anc(ppg_raw, df_imu, fs=400.0,\n",
    "                           # PPG minimal\n",
    "                           hp_cut=0.2, mains=50,\n",
    "                           # IMU preprocessing\n",
    "                           acc_fc=20, gyro_fc=40, static_idx=None, static_secs=2.0,\n",
    "                           # ANC\n",
    "                           anc_mu=0.02,\n",
    "                           thr_acc_g=1.3, thr_gyro_dps=150, thr_jerk=2.0, pad_sec=0.25,\n",
    "                           return_weights=True):\n",
    "\n",
    "    Full pipeline for ANC using IMU:\n",
    "      1) PPG minimal preprocessing (high-pass + optional mains notch; no narrow band)\n",
    "      2) IMU preprocessing with static bias removal + LP + EKF roll/pitch + gravity removal -> a_dyn & metrics\n",
    "      3) Build multi-reference Xref from IMU features; Z-score columns\n",
    "      4) Build motion window; NLMS only adapts when 'motion' is present\n",
    "      5) NLMS multi-input to obtain cleaned PPG residual\n",
    "\n",
    "    Returns dict:\n",
    "      ppg_min : minimally preprocessed PPG\n",
    "      imu     : dict from imu_preprocess_with_kf(...)\n",
    "      anc     : dict with y_clean, W (weights), motion_win, Xref_z, zscore params, thresholds, mu\n",
    " \n",
    "    # ---- 1) PPG minimal（你已有 preprocess_ppg_min） ----\n",
    "    ppg_min = preprocess_ppg_min(ppg_raw, fs=fs, hp_cut=hp_cut, mains=mains)\n",
    "\n",
    "    # ---- 2) IMU preprocessing（你已有 imu_preprocess_with_kf） ----\n",
    "    imu_out = imu_preprocess_with_kf(df_imu, fs=fs,\n",
    "                                     acc_fc=acc_fc, gyro_fc=gyro_fc,\n",
    "                                     static_secs=static_secs, static_idx=static_idx)\n",
    "\n",
    "    # ---- 3) Xref + Z-score ----\n",
    "    Xref, feat_names = build_xref_from_imu(imu_out)\n",
    "    Xref_z, mu_x, sd_x = standardize_cols(Xref)\n",
    "\n",
    "    # ---- 4) Motion window ----\n",
    "    motion_win = build_motion_window(\n",
    "        imu_out['AccMag'], imu_out['GyroMag'], imu_out['JerkMag'],\n",
    "        thr_acc_g=thr_acc_g, thr_gyro_dps=thr_gyro_dps, thr_jerk=thr_jerk,\n",
    "        fs=fs, pad_sec=pad_sec\n",
    "    )\n",
    "\n",
    "    # ---- 5) NLMS multi-input ----\n",
    "    y_clean, W = nlms_multi(ppg_min, Xref_z, mu=anc_mu, win=motion_win, return_weights=return_weights)\n",
    "\n",
    "    return dict(\n",
    "        ppg_min = ppg_min,\n",
    "        imu     = imu_out,\n",
    "        anc     = dict(\n",
    "            y_clean   = y_clean,\n",
    "            W         = W,\n",
    "            Xref_z    = Xref_z,\n",
    "            Xref_mu   = mu_x,\n",
    "            Xref_sd   = sd_x,\n",
    "            feat_names= feat_names,\n",
    "            motion_win= motion_win,\n",
    "            mu        = anc_mu,\n",
    "            thr       = dict(acc_g=thr_acc_g, gyro_dps=thr_gyro_dps, jerk=thr_jerk),\n",
    "            pad_sec   = pad_sec\n",
    "        )\n",
    "    )\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9116cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal, interpolate\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# =========================================================\n",
    "# 1) Baseline utilities\n",
    "# =========================================================\n",
    "def welch_psd(x, fs, fmax=None, nperseg=None, noverlap=0.5):\n",
    "    \"\"\"Compute Welch PSD with Hann window and optional fmax clip.\"\"\"\n",
    "    x = np.asarray(x, float).ravel()\n",
    "    if nperseg is None:\n",
    "        nperseg = min(len(x), int(8*fs))  # ~8s window by default\n",
    "    nlap = int(noverlap * nperseg) if isinstance(noverlap, float) else int(noverlap)\n",
    "    f, Pxx = signal.welch(x, fs=fs, window=\"hann\", nperseg=nperseg, noverlap=nlap)\n",
    "    if fmax is not None:\n",
    "        m = f <= float(fmax)\n",
    "        f, Pxx = f[m], Pxx[m]\n",
    "    return f, Pxx + 1e-18\n",
    "\n",
    "def estimate_hr_freq_welch(x, fs, fmin=0.6, fmax=3.5):\n",
    "    \"\"\"Rough HR frequency estimate (Hz) from PPG via Welch.\"\"\"\n",
    "    f, P = welch_psd(x, fs, fmax=fmax)\n",
    "    band = (f >= fmin) & (f <= fmax)\n",
    "    if not np.any(band):\n",
    "        return np.nan\n",
    "    j = np.argmax(P[band])\n",
    "    f_hr = float(f[band][j])\n",
    "    return f_hr\n",
    "\n",
    "# =========================================================\n",
    "# 2) EMD (sifting) + CEEMD-lite reference construction\n",
    "# =========================================================\n",
    "def _local_extrema(x):\n",
    "    \"\"\"Return indices of local maxima and minima of a 1D array.\"\"\"\n",
    "    # maxima: x[i-1] < x[i] >= x[i+1]; minima: x[i-1] > x[i] <= x[i+1]\n",
    "    dx = np.diff(x)\n",
    "    # zero-crossings of derivative with sign check\n",
    "    max_idx = np.where((np.hstack([dx, 0]) < 0) & (np.hstack([0, dx]) > 0))[0]\n",
    "    min_idx = np.where((np.hstack([dx, 0]) > 0) & (np.hstack([0, dx]) < 0))[0]\n",
    "    # remove endpoints (can be unstable)\n",
    "    max_idx = max_idx[(max_idx > 1) & (max_idx < len(x)-2)]\n",
    "    min_idx = min_idx[(min_idx > 1) & (min_idx < len(x)-2)]\n",
    "    return max_idx, min_idx\n",
    "\n",
    "def _sift_once(x, t):\n",
    "    \"\"\"One sifting step: build upper/lower envelopes via cubic spline; return mean envelope.\"\"\"\n",
    "    max_idx, min_idx = _local_extrema(x)\n",
    "    if len(max_idx) < 2 or len(min_idx) < 2:\n",
    "        return None  # cannot build envelopes -> stop\n",
    "    # Add endpoints by mirroring to mitigate edge effect\n",
    "    def _pad(idx):\n",
    "        return np.r_[0, idx, len(x)-1]\n",
    "    xi_max, xi_min = _pad(max_idx), _pad(min_idx)\n",
    "\n",
    "    # Envelope interpolation\n",
    "    cs_max = interpolate.CubicSpline(t[xi_max], x[xi_max], bc_type=\"natural\")\n",
    "    cs_min = interpolate.CubicSpline(t[xi_min], x[xi_min], bc_type=\"natural\")\n",
    "    env_up = cs_max(t)\n",
    "    env_lo = cs_min(t)\n",
    "    m = 0.5 * (env_up + env_lo)\n",
    "    return m\n",
    "\n",
    "def emd_sift(x, fs, max_imfs=6, max_sift=10, sd_thresh=0.2):\n",
    "    \"\"\"\n",
    "    Basic EMD sifting to extract IMFs from signal x.\n",
    "    - max_imfs: maximum IMFs to extract\n",
    "    - max_sift: max sifting iterations per IMF\n",
    "    - sd_thresh: stop criterion (SD index)\n",
    "    Returns: imfs (list of arrays), residual (array)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float).ravel()\n",
    "    t = np.arange(len(x)) / fs\n",
    "    imfs = []\n",
    "    r = x.copy()\n",
    "\n",
    "    for _ in range(max_imfs):\n",
    "        h = r.copy()\n",
    "        for _ in range(max_sift):\n",
    "            m = _sift_once(h, t)\n",
    "            if m is None:\n",
    "                break\n",
    "            h_prev = h\n",
    "            h = h - m\n",
    "            sd = np.sum((h_prev - h)**2) / (np.sum(h_prev**2) + 1e-18)\n",
    "            if sd < sd_thresh:\n",
    "                break\n",
    "        # Check stoppage: not enough extrema to continue\n",
    "        max_idx, min_idx = _local_extrema(h)\n",
    "        if len(max_idx) + len(min_idx) < 2:\n",
    "            break\n",
    "        imfs.append(h)\n",
    "        r = r - h\n",
    "        # if residual is monotonic-ish, stop\n",
    "        mx, mn = _local_extrema(r)\n",
    "        if len(mx) < 1 or len(mn) < 1:\n",
    "            break\n",
    "\n",
    "    return imfs, r\n",
    "\n",
    "def ceemd_reference(x, fs, pairs=6, noise_ratio=0.2, max_imfs=6, max_sift=10, sd_thresh=0.2,\n",
    "                    protect_hr=True, protect_bw=0.25, protect_harmonics=2,\n",
    "                    low_motion_hz=0.4, high_motion_hz=6.0):\n",
    "    \"\"\"\n",
    "    CEEMD-lite: build motion-artifact reference u(n) by averaging IMFs over complementary noise pairs.\n",
    "    Steps:\n",
    "      1) For i in 1..pairs: add white noise 'n' (std=noise_ratio*std(x)) -> x+n and x-n\n",
    "      2) EMD both, then average IMFs level-wise\n",
    "      3) Classify IMFs: protect cardiac IMFs near HR (and its harmonics), sum the rest as 'u_ref'\n",
    "    Returns:\n",
    "      dict with: u_ref, imfs_avg (list), residual, motion_idx, cardiac_idx, f_hr\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float).ravel()\n",
    "    N = len(x)\n",
    "    sigma = np.std(x) + 1e-12\n",
    "    imfs_accum = None\n",
    "    max_levels = 0\n",
    "\n",
    "    rng = np.random.default_rng(2025)\n",
    "    for _ in range(pairs):\n",
    "        n = rng.standard_normal(N) * (noise_ratio * sigma)\n",
    "        for sign in (+1.0, -1.0):\n",
    "            imfs, res = emd_sift(x + sign * n, fs, max_imfs=max_imfs, max_sift=max_sift, sd_thresh=sd_thresh)\n",
    "            L = len(imfs)\n",
    "            if L == 0:\n",
    "                continue\n",
    "            if imfs_accum is None:\n",
    "                max_levels = L\n",
    "                imfs_accum = [imfs[k].astype(float) for k in range(L)]\n",
    "            else:\n",
    "                # extend to the current max levels\n",
    "                if L > max_levels:\n",
    "                    # pad previous with zeros\n",
    "                    imfs_accum += [np.zeros_like(x) for _ in range(L - max_levels)]\n",
    "                    max_levels = L\n",
    "                # accumulate\n",
    "                for k in range(L):\n",
    "                    if k < len(imfs_accum):\n",
    "                        imfs_accum[k] = imfs_accum[k] + imfs[k]\n",
    "                    else:\n",
    "                        imfs_accum.append(imfs[k].copy())\n",
    "\n",
    "    if imfs_accum is None or max_levels == 0:\n",
    "        # fallback: no IMFs -> reference is zeros\n",
    "        return dict(u_ref=np.zeros_like(x), imfs_avg=[], residual=x.copy(),\n",
    "                    motion_idx=[], cardiac_idx=[], f_hr=np.nan)\n",
    "\n",
    "    # Average over (2*pairs) realizations\n",
    "    denom = 2.0 * pairs\n",
    "    imfs_avg = [imf / denom for imf in imfs_accum]\n",
    "    residual = x - np.sum(imfs_avg, axis=0)\n",
    "\n",
    "    # --- IMF selection: protect cardiac; others -> motion set M ---\n",
    "    # rough HR (Hz) to define protect bands\n",
    "    f_hr = estimate_hr_freq_welch(x, fs, fmin=0.6, fmax=3.5)\n",
    "    motion_idx, cardiac_idx = [], []\n",
    "    for k, ck in enumerate(imfs_avg):\n",
    "        # dominant freq of IMF k\n",
    "        f, P = welch_psd(ck, fs, fmax=8.0)\n",
    "        fk = f[np.argmax(P)]\n",
    "        is_cardiac = False\n",
    "        if protect_hr and np.isfinite(f_hr):\n",
    "            # protect f_hr ± protect_bw and its harmonics\n",
    "            for h in range(1, protect_harmonics + 1):\n",
    "                if abs(fk - h * f_hr) <= protect_bw:\n",
    "                    is_cardiac = True\n",
    "                    break\n",
    "        # low drift and high wideband -> motion by default\n",
    "        if not is_cardiac and (fk <= low_motion_hz or fk >= high_motion_hz):\n",
    "            motion_idx.append(k)\n",
    "        elif is_cardiac:\n",
    "            cardiac_idx.append(k)\n",
    "        else:\n",
    "            # decide by energy overlap with a HR-bandpass version of x\n",
    "            b, a = signal.butter(2, [0.6/(0.5*fs), 3.5/(0.5*fs)], btype='band')\n",
    "            x_hr = signal.filtfilt(b, a, x)\n",
    "            corr = np.corrcoef(ck, x_hr)[0,1]\n",
    "            (cardiac_idx if abs(corr) >= 0.2 else motion_idx).append(k)\n",
    "\n",
    "    # motion reference as sum of motion IMFs + residual below HR band\n",
    "    u_ref = np.zeros_like(x)\n",
    "    for k in motion_idx:\n",
    "        u_ref += imfs_avg[k]\n",
    "    # (Optional) If residual is very slow, treat as drift -> include\n",
    "    f_res, P_res = welch_psd(residual, fs, fmax=2.0)\n",
    "    if f_res[np.argmax(P_res)] < 0.4:\n",
    "        u_ref += residual\n",
    "\n",
    "    return dict(u_ref=u_ref, imfs_avg=imfs_avg, residual=residual,\n",
    "                motion_idx=motion_idx, cardiac_idx=cardiac_idx, f_hr=f_hr)\n",
    "\n",
    "# =========================================================\n",
    "# 3) NLMS ANC (stable, leaky)\n",
    "# =========================================================\n",
    "def nlms_anc(x, u_ref, L=32, mu=0.1, eps=1e-6, leak=1e-4):\n",
    "    \"\"\"\n",
    "    Normalized LMS ANC: estimate motion m^(n) = w^T u(n) and clean e = x - m^.\n",
    "      x    : observed PPG (N,)\n",
    "      u_ref: reference (N,) – from CEEMD motion estimate\n",
    "      L    : FIR length (tapped delay line)\n",
    "      mu   : NLMS step size (0<mu<2; typical 0.05~0.5)\n",
    "      leak : small leakage to stabilize weights\n",
    "    Returns: y (motion estimate), e (clean), W (weight history)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, float).ravel()\n",
    "    u = np.asarray(u_ref, float).ravel()\n",
    "    N = len(x)\n",
    "    y = np.zeros(N)\n",
    "    e = np.zeros(N)\n",
    "    W = np.zeros((N, L))\n",
    "    w = np.zeros(L)\n",
    "\n",
    "    # Pre-build delayed matrix (Toeplitz-like) efficiently\n",
    "    buf = np.zeros(L)\n",
    "    for n in range(N):\n",
    "        # update tapped-delay line: u[n], u[n-1], ..., u[n-L+1]\n",
    "        buf[1:] = buf[:-1]\n",
    "        buf[0] = u[n]\n",
    "        y[n] = float(np.dot(w, buf))\n",
    "        e[n] = x[n] - y[n]\n",
    "        denom = eps + np.dot(buf, buf)\n",
    "        w = (1.0 - leak) * w + (mu * e[n] * buf) / denom\n",
    "        W[n] = w\n",
    "    return y, e, W\n",
    "\n",
    "# =========================================================\n",
    "# 4) End-to-end: CEEMD reference + LMS ANC\n",
    "# =========================================================\n",
    "def remove_ma_cemd_lms(ppg, fs=400,\n",
    "                       ce_pairs=6, ce_noise_ratio=0.2, ce_max_imfs=6,\n",
    "                       ce_max_sift=10, ce_sd=0.2,\n",
    "                       protect_bw=0.25, protect_harm=2,\n",
    "                       low_motion_hz=0.4, high_motion_hz=6.0,\n",
    "                       lms_L=32, lms_mu=0.1, lms_leak=1e-4):\n",
    "    \"\"\"\n",
    "    Full pipeline:\n",
    "      - CEEMD-lite -> motion reference u_ref\n",
    "      - NLMS ANC   -> y (motion estimate), e (clean PPG)\n",
    "    Returns dict with: x, u_ref, y_ma, e_clean, debug fields\n",
    "    \"\"\"\n",
    "    x = np.asarray(ppg, float).ravel()\n",
    "\n",
    "    ce = ceemd_reference(\n",
    "        x, fs,\n",
    "        pairs=ce_pairs, noise_ratio=ce_noise_ratio,\n",
    "        max_imfs=ce_max_imfs, max_sift=ce_max_sift, sd_thresh=ce_sd,\n",
    "        protect_hr=True, protect_bw=protect_bw, protect_harmonics=protect_harm,\n",
    "        low_motion_hz=low_motion_hz, high_motion_hz=high_motion_hz\n",
    "    )\n",
    "    u_ref = ce['u_ref']\n",
    "\n",
    "    y_ma, e_clean, W = nlms_anc(x, u_ref, L=lms_L, mu=lms_mu, leak=lms_leak)\n",
    "\n",
    "    return dict(\n",
    "        x=x, u_ref=u_ref, y_ma=y_ma, e_clean=e_clean, W=W,\n",
    "        ce=ce\n",
    "    )\n",
    "\n",
    "# =========================================================\n",
    "# 5) Dash/Plotly: single shared axis figure (raw / MA / clean)\n",
    "# =========================================================\n",
    "def build_cemd_lms_figure(ppg, fs, out_dict, height=420, title=\"CE(M)D + LMS ANC (shared axis)\"):\n",
    "    \"\"\"\n",
    "    Build a Plotly figure for Dash that overlays:\n",
    "        - Raw PPG x(n)\n",
    "        - Motion estimate y(n) (ANC output)\n",
    "        - Clean PPG e(n) = x - y\n",
    "    All on a single shared y-axis & time x-axis.\n",
    "    \"\"\"\n",
    "    x = out_dict[\"x\"]\n",
    "    y_ma = out_dict[\"y_ma\"]\n",
    "    e = out_dict[\"e_clean\"]\n",
    "    t = np.arange(len(x)) / float(fs)\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=t, y=x, name=\"PPG raw\", line=dict(color=\"purple\", width=1.2)))\n",
    "    fig.add_trace(go.Scatter(x=t, y=y_ma, name=\"MA estimate (ANC)\", line=dict(color=\"orange\", width=1)))\n",
    "    fig.add_trace(go.Scatter(x=t, y=e, name=\"PPG clean\", line=dict(color=\"green\", width=1.4)))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        height=height,\n",
    "        margin=dict(l=50, r=30, t=50, b=40),\n",
    "        paper_bgcolor=\"white\",\n",
    "        plot_bgcolor=\"white\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0)\n",
    "    )\n",
    "    fig.update_xaxes(title=\"Time (s)\", showgrid=True, gridcolor=\"rgba(0,0,0,0.08)\")\n",
    "    fig.update_yaxes(title=\"Amplitude\", showgrid=True, gridcolor=\"rgba(0,0,0,0.08)\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c15d1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== HR/HRV compare (strict) – core helpers ====\n",
    "\n",
    "# 统一的“已知特征键”清单（用于并集表的排序与补齐）\n",
    "_HRV_TD_KEYS  = ['mhr','mrri','sdnn','rmssd','nn50','pnn50','sdsd']\n",
    "_HRV_FD_KEYS  = ['vlf','lf','hf','total_power','lfnu','hfnu','lf_hf']\n",
    "_HRV_NL_KEYS  = ['sd1','sd2']\n",
    "\n",
    "_HRVA_TD_KEYS   = [\n",
    "    'mean_nni','sdnn','sdsd','nni_50','pnni_50','nni_20','pnni_20','rmssd',\n",
    "    'median_nni','range_nni','cvsd','cvnni','mean_hr','max_hr','min_hr','std_hr'\n",
    "]\n",
    "_HRVA_GEOM_KEYS = ['triangular_index','tinn']\n",
    "_HRVA_FD_KEYS   = ['vlf','lf','hf','total_power','lfnu','hfnu','lf_hf','lf_hf_ratio','lf_hr_ratio']\n",
    "_HRVA_NL_KEYS   = ['csi','cvi','mcsi','sd1','sd2','sd2_sd1','sd1_sd2','sampen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b59cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fmt_float(v: Any) -> Any:\n",
    "    \"\"\"开发期轻量格式化：保留 4 位小数；NaN/Inf -> None。\"\"\"\n",
    "    if isinstance(v, float):\n",
    "        if math.isnan(v) or math.isinf(v):\n",
    "            return None\n",
    "        return float(f\"{v:.4f}\")\n",
    "    return v\n",
    "\n",
    "\n",
    "def ppi_from_peaks(\n",
    "    peaks: Iterable[float],\n",
    "    fs: float = FS,\n",
    "    peaks_are_indices: bool = False,\n",
    "    ppi_min_ms: float = 300.0,\n",
    "    ppi_max_ms: float = 2000.0,\n",
    "    deduplicate_ms: Optional[float] = 20,\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    用峰位置（样本索引或秒）生成 PPI(ms)；严格模式：不做异常捕捉。\n",
    "    - peaks: 峰序列（索引或秒）\n",
    "    - fs: 采样率（peaks 为索引时必填）\n",
    "    - ppi_min_ms, ppi_max_ms: 合理范围过滤（默认 300–2000ms）\n",
    "    - deduplicate_ms: 可选，去掉彼此过近的相邻 PPI（如 200ms）\n",
    "    \"\"\"\n",
    "    peaks = list(peaks)\n",
    "    if len(peaks) < 2:\n",
    "        return []\n",
    "    t = [p / float(fs) for p in peaks] if peaks_are_indices else [float(p) for p in peaks]\n",
    "    t = sorted(t)  # 保证单调\n",
    "    ppi_ms = [(t[i] - t[i - 1]) * 1000.0 for i in range(1, len(t))]\n",
    "    ppi_ms = [x for x in ppi_ms if (ppi_min_ms <= x <= ppi_max_ms)]\n",
    "    if deduplicate_ms and deduplicate_ms > 0:\n",
    "        clean: List[float] = []\n",
    "        for x in ppi_ms:\n",
    "            if not clean or abs(x - clean[-1]) >= deduplicate_ms:\n",
    "                clean.append(x)\n",
    "        ppi_ms = clean\n",
    "    return ppi_ms\n",
    "\n",
    "def preprocess_ppi_for_hrv(\n",
    "    ppi_ms: List[float],\n",
    "    apply_quotient: bool = True,\n",
    "    threshold_strength: str = \"medium\",\n",
    "    local_median_size: int = 5,\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    hrv（JOSS 包）预处理：quotient → threshold_filter（Kubios 风格，样条替换）。\n",
    "    返回 NN 间期（ms）列表。\n",
    "    \"\"\"\n",
    "    rri = RRi(ppi_ms)\n",
    "    if apply_quotient:\n",
    "        rri = quotient(rri)  # 相邻比值法，去掉突变伪迹\n",
    "    rri = threshold_filter(rri, threshold=threshold_strength, local_median_size=local_median_size)\n",
    "    return list(rri)  # RRi 可迭代，转为 list[ms]\n",
    "\n",
    "def preprocess_ppi_for_hrvanalysis(\n",
    "    ppi_ms: List[float],\n",
    "    ppi_min_ms: float = 300.0,\n",
    "    ppi_max_ms: float = 2000.0,\n",
    "    ectopic_method: str = \"malik\",\n",
    "    interpolation_method: str = \"linear\",\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    hrvanalysis 预处理：remove_outliers → remove_ectopic_beats → interpolate_nan_values。\n",
    "    返回 NN 间期（ms）列表。\n",
    "    \"\"\"\n",
    "    rr = list(ppi_ms)\n",
    "    rr = remove_outliers(rr, low_rri=ppi_min_ms, high_rri=ppi_max_ms)\n",
    "    rr = remove_ectopic_beats(rr, method=ectopic_method)\n",
    "    rr = interpolate_nan_values(rr, interpolation_method=interpolation_method)\n",
    "    return rr\n",
    "\n",
    "def hrv_features_via_hrv(ppi_ms: List[float]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    用 hrv（JOSS）计算：时间域 + 频域 + 非线性。\n",
    "    严格模式：如出错会直接抛异常。\n",
    "    \"\"\"\n",
    "    rri = RRi(ppi_ms)\n",
    "    out: Dict[str, Any] = {}\n",
    "    out.update({k: _fmt_float(v) for k, v in time_domain(rri).items()})\n",
    "    out.update({k: _fmt_float(v) for k, v in frequency_domain(rri).items()})\n",
    "    out.update({k: _fmt_float(v) for k, v in non_linear(rri).items()})\n",
    "    return out\n",
    "\n",
    "\n",
    "def hrv_features_via_hrvanalysis(ppi_ms: List[float]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    用 hrvanalysis（Aura）计算：时间域 + 几何域 + 频域 + 非线性（CSI/CVI/SD1/SD2/SampEn）。\n",
    "    严格模式：如出错会直接抛异常。\n",
    "    \"\"\"\n",
    "    out: Dict[str, Any] = {}\n",
    "    out.update({k: _fmt_float(v) for k, v in get_time_domain_features(ppi_ms).items()})\n",
    "    out.update({k: _fmt_float(v) for k, v in get_geometrical_features(ppi_ms).items()})\n",
    "    out.update({k: _fmt_float(v) for k, v in get_frequency_domain_features(ppi_ms).items()})\n",
    "\n",
    "    csi = get_csi_cvi_features(ppi_ms)\n",
    "    out.update({k.lower(): _fmt_float(v) for k, v in csi.items()})\n",
    "\n",
    "    pc = get_poincare_plot_features(ppi_ms)\n",
    "    for k, v in pc.items():\n",
    "        key = k.lower().replace(' ', '_').replace('/', '_')  # 统一键名：sd1, sd2, sd2_sd1 等\n",
    "        out[key] = _fmt_float(v)\n",
    "\n",
    "    se = get_sampen(ppi_ms)\n",
    "    if isinstance(se, dict):\n",
    "        for k, v in se.items():\n",
    "            out[f\"sampen_{str(k).lower()}\"] = _fmt_float(v)\n",
    "    else:\n",
    "        out[\"sampen\"] = _fmt_float(se)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def hrv_feature_union_rows(hrv_feats: Dict[str, Any], hrva_feats: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    构建并集表（feature | hrv | hrvanalysis）。\n",
    "    注意：严格模式不生成“Fail”，缺项以 'NS' 标示；真正失败会在上游直接抛异常。\n",
    "    \"\"\"\n",
    "    known_hrv = set(_HRV_TD_KEYS + _HRV_FD_KEYS + _HRV_NL_KEYS)\n",
    "    known_hrva = set(_HRVA_TD_KEYS + _HRVA_GEOM_KEYS + _HRVA_FD_KEYS + _HRVA_NL_KEYS)\n",
    "    keys = known_hrv | known_hrva | set(hrv_feats.keys()) | set(hrva_feats.keys())\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for k in sorted(keys):\n",
    "        rows.append({\n",
    "            \"feature\": k,\n",
    "            \"hrv\": hrv_feats.get(k, 'NS'),\n",
    "            \"hrvanalysis\": hrva_feats.get(k, 'NS'),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "\n",
    "# ---------------- 端到端：从 aboy_info_ir 到 Dash 表格行（严格，近似统一预处理） ----------------\n",
    "\n",
    "def hrv_compare_from_aboy_ir(\n",
    "    aboy_info_ir: Dict[str, Any],\n",
    "    fs_ppg: float,\n",
    "    peaks_are_indices: bool = True,\n",
    "    ppi_min_ms: float = 300.0,\n",
    "    ppi_max_ms: float = 2000.0,\n",
    "    deduplicate_ms: Optional[float] = None,\n",
    "    # 预处理对齐参数（两包各自的“本家方式”）\n",
    "    preprocess = False,\n",
    "    hrv_apply_quotient: bool = True,\n",
    "    hrv_threshold_strength: str = \"medium\",\n",
    "    hrv_local_median_size: int = 5,\n",
    "    hrva_ectopic_method: str = \"malik\",\n",
    "    hrva_interpolation_method: str = \"linear\",\n",
    ") -> Tuple[List[float], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    流程：\n",
    "      peaks_global → 原始 PPI(ms)\n",
    "      → hrv 预处理（quotient + threshold_filter）→ hrv 指标\n",
    "      → hrvanalysis 预处理（去异常 + 去异位搏 + 插值）→ hrvanalysis 指标\n",
    "      → 合表（feature | hrv | hrvanalysis）\n",
    "    返回：(ppi_ms_raw, rows)\n",
    "    \"\"\"\n",
    "    peaks = aboy_info_ir['peaks_global']\n",
    "    ppi_ms_raw = ppi_from_peaks(\n",
    "        peaks=peaks,\n",
    "        fs=fs_ppg,\n",
    "        peaks_are_indices=peaks_are_indices,\n",
    "        ppi_min_ms=ppi_min_ms,\n",
    "        ppi_max_ms=ppi_max_ms,\n",
    "        deduplicate_ms=deduplicate_ms,\n",
    "    )\n",
    "\n",
    "    # 各自“本家预处理”，目标是近似统一的 NN 输入效果\n",
    "    if preprocess:\n",
    "        nn_hrv  = preprocess_ppi_for_hrv(\n",
    "            ppi_ms_raw,\n",
    "            apply_quotient=hrv_apply_quotient,\n",
    "            threshold_strength=hrv_threshold_strength,\n",
    "            local_median_size=hrv_local_median_size,\n",
    "        )\n",
    "        nn_hrva = preprocess_ppi_for_hrvanalysis(\n",
    "            ppi_ms_raw,\n",
    "            ppi_min_ms=ppi_min_ms,\n",
    "            ppi_max_ms=ppi_max_ms,\n",
    "            ectopic_method=hrva_ectopic_method,\n",
    "            interpolation_method=hrva_interpolation_method,\n",
    "        )\n",
    "    else:\n",
    "        nn_hrv = ppi_ms_raw\n",
    "        nn_hrva = ppi_ms_raw\n",
    "\n",
    "    # 各自计算（严格模式：失败会直接抛异常）\n",
    "    feats_hrv  = hrv_features_via_hrv(nn_hrv)\n",
    "    feats_hrva = hrv_features_via_hrvanalysis(nn_hrva)\n",
    "\n",
    "    rows = hrv_feature_union_rows(feats_hrv, feats_hrva)\n",
    "    return ppi_ms_raw, rows\n",
    "\n",
    "\n",
    "def build_hrv_compare_table(rows: List[Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    Dash DataTable 组件；列顺序：特征 | hrv | hrvanalysis。\n",
    "    \"\"\"\n",
    "    return dash_table.DataTable(\n",
    "        id=\"hrv-compare-table\",\n",
    "        columns=[\n",
    "            {\"name\": \"Feature\", \"id\": \"feature\"},\n",
    "            {\"name\": \"hrv\", \"id\": \"hrv\"},\n",
    "            {\"name\": \"hrvanalysis\", \"id\": \"hrvanalysis\"},\n",
    "        ],\n",
    "        data=rows,\n",
    "        style_table={\"overflowX\": \"auto\"},\n",
    "        style_cell={\"fontFamily\": \"monospace\", \"fontSize\": 13, \"padding\": \"6px\"},\n",
    "        style_header={\"fontWeight\": \"bold\"},\n",
    "        sort_action=\"native\",\n",
    "        filter_action=\"native\",\n",
    "        page_size=20,\n",
    "    )\n",
    "# ================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe6bed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------Dash Func-------------------\n",
    "def get_folder_options():\n",
    "    \"\"\"遍历 DEFAULT_FOLDER_MAIN 下的子文件夹，生成 Dropdown 选项；确保包含 DEFAULT_FOLDER。\"\"\"\n",
    "    paths = []\n",
    "    if os.path.isdir(DEFAULT_FOLDER_MAIN):\n",
    "        for name in sorted(os.listdir(DEFAULT_FOLDER_MAIN)):\n",
    "            p = os.path.join(DEFAULT_FOLDER_MAIN, name)\n",
    "            if os.path.isdir(p):\n",
    "                paths.append(p)\n",
    "    # 确保 DEFAULT_FOLDER 在选项里（即使不在 DEFAULT_FOLDER_MAIN 下，也加入）\n",
    "    if DEFAULT_FOLDER and os.path.exists(DEFAULT_FOLDER) and DEFAULT_FOLDER not in paths:\n",
    "        paths.insert(0, DEFAULT_FOLDER)\n",
    "    # label 显示目录名，value 为完整路径\n",
    "    return [{'label': os.path.basename(p) or p, 'value': p} for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c6726a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dash App Layout ---\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Auto‑launch browser window\n",
    "webbrowser.open(f\"http://localhost:{PORT}\")\n",
    "\n",
    "folder_options = get_folder_options()\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"PPG Signal Analysis Dashboard\", style={\"marginTop\": 0}),\n",
    "\n",
    "    # Input block: folder selection\n",
    "    html.Div([\n",
    "        html.Label(\"📁 Select Folder:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='folder-path',\n",
    "            options=folder_options,\n",
    "            value=DEFAULT_FOLDER,\n",
    "            clearable=False,\n",
    "            placeholder='Select data folder',\n",
    "            style={'width': '80%'}\n",
    "        ),\n",
    "    ]),\n",
    "\n",
    "    # Dropdown for file list\n",
    "    html.Div([\n",
    "        html.Label(\"📄 Select File:\"),\n",
    "        dcc.Dropdown(id='file-list')\n",
    "    ]),\n",
    "    \n",
    "    # Input block: folder selection\n",
    "    html.Div([\n",
    "        html.Label(\"📁 Select Folder for bias:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='folder-path_bias',\n",
    "            options=folder_options,\n",
    "            value=DEFAULT_FOLDER,\n",
    "            clearable=False,\n",
    "            placeholder='Select bias folder',\n",
    "            style={'width': '80%'}\n",
    "        ),\n",
    "    ]),\n",
    "\n",
    "    # Dropdown for file list\n",
    "    html.Div([\n",
    "        html.Label(\"📄 Select File for bias:\"),\n",
    "        dcc.Dropdown(id='file-list_bias')\n",
    "    ]),\n",
    "\n",
    "    # Input block: column name configuration\n",
    "    html.Div([\n",
    "        html.Label(\"🔢 Enter IR Column Name:\"),\n",
    "        dcc.Input(id='ir-column', type='text', value='IR'),\n",
    "        html.Label(\"🔢 Enter RED Column Name:\"),\n",
    "        dcc.Input(id='red-column', type='text', value='RED'),\n",
    "    ], style={'marginTop': 20}),\n",
    "\n",
    "    # Filter and processing parameters\n",
    "    html.Div([\n",
    "        html.Label(\"🎛 Filter Controls:\"),\n",
    "        html.Div([\"Bandpass Order:\", dcc.Slider(1, 10, 1, value=3, id='bandpass-order')]),\n",
    "        html.Div([\"Bandpass Lowcut:\", dcc.Slider(0, 1, 0.1, value=0.5, id='bandpass-lowcut')]),\n",
    "        html.Div([\"Bandpass highcut:\", dcc.Slider(3, 8, 0.2, value=5, id='bandpass-highcut')]),\n",
    "        html.Div([\"Wavelet Level:\", dcc.Slider(1, 6, 1, value=4, id='wavelet-level')]),\n",
    "        html.Div([\"Highpass Cutoff (Hz):\", dcc.Slider(0.1, 2.0, 0.1, value=0.5, id='highpass-cutoff')]),\n",
    "        html.Div([\"Notch Frequency:\", dcc.Slider(45, 65, 1, value=50, id='notch-freq')])\n",
    "    ], style={'marginTop': 30}),\n",
    "    \n",
    "    html.Div([\n",
    "        html.Div([\"Enable Notch Filter:\", dcc.Checklist(options=[{\"label\": \"Enable\", \"value\": \"on\"}], id='notch-enable')]),\n",
    "        html.Div([\"Enable Wavelet Denoising:\", dcc.Checklist(options=[{\"label\": \"Enable\", \"value\": \"on\"}], id='wavelet-enable')]),\n",
    "        html.Div([\"Enable High Pass Filter:\", dcc.Checklist(options=[{\"label\": \"Enable\", \"value\": \"on\"}], id='Highpass-enable')]),\n",
    "        html.Div([\"FFT Max Hz\", dcc.Slider(id=\"fmax\", min=1, max=200, step=None, marks={x: str(x) for x in (1, 5, 8, 20, 50, 100, 200)}, value=8)],style={\"width\":\"960px\"})\n",
    "    ], style={\"display\":\"flex\", \"gap\":\"16px\", \"alignItems\":\"center\", \"flexWrap\":\"wrap\", \"marginTop\": 8}),\n",
    "\n",
    "    # ---- IMU & ANC & Aboy++ controls ----\n",
    "    html.Div([\n",
    "        html.H4(\"IMU Classifier\"),\n",
    "        html.Div([\"Enable\", dcc.Checklist([{\"label\":\"on\",\"value\":\"on\"}],value=[\"on\"], id=\"imu_on\")]),\n",
    "        html.Div([\"Window (s)\", dcc.Slider(id=\"win_sec\", min=0.4, max=10.0, step=0.2, value=1.0)]),          #, style={\"width\":\"240px\"}),\n",
    "        html.Div([\"Hop (s)\", dcc.Slider(id=\"hop_sec\", min=0.1, max=5.0, step=0.2, value=0.5)]),    #, style={\"width\":\"240px\"}),\n",
    "\n",
    "        html.H4(\"ANC (NLMS)\"),\n",
    "        html.Div([\"Enable\", dcc.Checklist([{\"label\":\"on\",\"value\":\"on\"}],value=[\"off\"], id=\"anc_on\")]),\n",
    "        html.Div([\"Step μ\", dcc.Slider(id=\"anc_mu\", min=0.005, max=0.05, step=0.005, value=0.02)]),   #, style={\"width\":\"260px\"}),\n",
    "        html.Div([\"Gate pad (s)\", dcc.Slider(id=\"anc_pad\", min=0.0, max=0.5, step=0.05, value=0.25)]),   #, style={\"width\":\"260px\"}),\n",
    "\n",
    "        html.H4(\"Aboy++ (raw PPG)\"),\n",
    "        html.Div([\"Enable\", dcc.Checklist([{\"label\":\"on\",\"value\":\"on\"}],value=[\"on\"], id=\"aboy_on\")]),\n",
    "        html.Div([\"Amp percentile\", dcc.Slider(id=\"aboy_p\", min=50, max=90, step=5, value=65)]),     #, style={\"width\":\"260px\"}),\n",
    "        html.Div([\"Window (s)\", dcc.Slider(id=\"aboy_win\", min=5, max=15, step=1, value=10)]),        #, style={\"width\":\"260px\"})\n",
    "    ],style={'marginTop': 30}), #style={\"display\":\"flex\", \"gap\":\"16px\", \"alignItems\":\"center\", \"flexWrap\":\"wrap\", \"marginTop\": 8}),\n",
    "\n",
    "    html.Button(\"🚀 Analyze\", id='analyze', n_clicks=0, style={\"marginTop\": 8}),  # Button to trigger signal processing\n",
    "    html.Div(\"Preview Bias data\",id='preview-table_bias', style={'marginTop': 30}),  # Top 3-row preview of selected CSV\n",
    "    html.Div(\"Preview raw data\", id='preview-table', style={'marginTop': 30}),  # Top 3-row preview of selected CSV\n",
    "    html.Div(\"resultTable\", id='results-table',style={'marginTop': 30}),  # Output table with metrics\n",
    "    html.Div([\n",
    "        html.H4(\"HRV features analyse and compare\"),\n",
    "        html.Div(\"HRVTable\", id='HRV-table',style={'marginTop': 30}),\n",
    "    ],style={'marginTop': 30}),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='ppg-combined-plot'),  # Combined PPG with peaks overlay\n",
    "        dcc.Graph(id='ppg-clean-plot'),  # Cleaned IR signal with cleaned peaks\n",
    "        dcc.Graph(id=\"fig_aboy_hr\"),\n",
    "        dcc.Graph(id='ppg-ir-plot'),  # IR signal with detected peaks\n",
    "        dcc.Graph(id='ppg-red-plot'),  # RED signal\n",
    "        dcc.Graph(id='Comb-Freq-plot'),\n",
    "        dcc.Graph(id='IR-Freq-plot'),\n",
    "        #dcc.Graph(id='RED-Freq-plot'),\n",
    "        dcc.Graph(id='IMU-Time-plot'),\n",
    "       # dcc.Graph(id='acc-Time-plot'),\n",
    "        dcc.Graph(id='IMU-Freq-plot'),\n",
    "        #dcc.Graph(id='acc-Freq-plot'),\n",
    "        dcc.Graph(id=\"fig_imu_t\"),\n",
    "        dcc.Graph(id=\"fig_EMD_1\"),\n",
    "        dcc.Graph(id=\"fig_anc_t\"),\n",
    "        dcc.Graph(id=\"fig_anc_f\"),\n",
    "    ], style={\n",
    "        \"display\": \"grid\",\n",
    "        \"gridTemplateColumns\": \"1fr\", #1fr\",\n",
    "        \"gap\": \"14px\",\n",
    "        \"marginTop\": 12\n",
    "    })\n",
    "], style={'backgroundColor': 'white', 'padding': '20px'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38dcf73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Callback: Update File List ---\n",
    "@app.callback(\n",
    "    Output('file-list', 'options'),\n",
    "    Output('file-list', 'value'),\n",
    "    Input('folder-path', 'value'),\n",
    "    prevent_initial_call=False \n",
    ")\n",
    "def update_file_list(folder):\n",
    "    \"\"\"List CSV filenames in the selected directory for dropdown display.\"\"\"\n",
    "    if not folder or not os.path.exists(folder):\n",
    "        print(\"Wrong Path\")\n",
    "        return [], None\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith('.csv')])\n",
    "    opts = [{'label': f, 'value': f} for f in files]\n",
    "    default_val = files[0] if files else None\n",
    "    return opts, default_val\n",
    "\n",
    "# --- Callback: Update File List for bias ---\n",
    "@app.callback(\n",
    "    Output('file-list_bias', 'options'),\n",
    "    Output('file-list_bias', 'value'),\n",
    "    Input('folder-path_bias', 'value'),\n",
    "    prevent_initial_call=False\n",
    ")\n",
    "def update_file_list_bias(folder):\n",
    "    \"\"\"List CSV filenames in the selected directory for dropdown display (bias).\"\"\"\n",
    "    if not folder or not os.path.exists(folder):\n",
    "        print(\"Wrong Path\")\n",
    "        return [], None\n",
    "    files = sorted([f for f in os.listdir(folder) if f.endswith('.csv')])\n",
    "    opts = [{'label': f, 'value': f} for f in files]\n",
    "    default_val = files[0] if files else None\n",
    "    return opts, default_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Callback: Analyze File and Plot ---\n",
    "@app.callback(\n",
    "    [Output('preview-table_bias', 'children'), \n",
    "     Output('preview-table', 'children'), \n",
    "     Output('results-table', 'children'), \n",
    "     Output('HRV-table', 'children'), \n",
    "     Output('ppg-combined-plot', 'figure'),\n",
    "     Output('ppg-clean-plot', 'figure'),\n",
    "     Output(\"fig_aboy_hr\", 'figure'),\n",
    "     Output('ppg-ir-plot', 'figure'),\n",
    "     Output('ppg-red-plot', 'figure'),\n",
    "     Output('Comb-Freq-plot', 'figure'),\n",
    "     Output('IR-Freq-plot', 'figure'),\n",
    "     #Output('RED-Freq-plot', 'figure'),\n",
    "     Output('IMU-Time-plot', 'figure'),\n",
    "     #Output('acc-Time-plot', 'figure'),\n",
    "     Output('IMU-Freq-plot', 'figure'),\n",
    "     #Output('acc-Freq-plot', 'figure'),\n",
    "     Output(\"fig_imu_t\",  \"figure\"),\n",
    "     Output(\"fig_EMD_1\",  \"figure\"),\n",
    "     Output(\"fig_anc_t\",  \"figure\"),\n",
    "     Output(\"fig_anc_f\",  \"figure\"),\n",
    "     ],\n",
    "    Input('analyze', 'n_clicks'),\n",
    "    State('folder-path', 'value'),\n",
    "    State('file-list', 'value'),\n",
    "    State('folder-path_bias', 'value'),\n",
    "    State('file-list_bias', 'value'),\n",
    "    State('ir-column', 'value'),\n",
    "    State('red-column', 'value'),\n",
    "    State('bandpass-order', 'value'),\n",
    "    State('bandpass-lowcut', 'value'),\n",
    "    State('bandpass-highcut', 'value'),\n",
    "    State('wavelet-level', 'value'),\n",
    "    State('highpass-cutoff', 'value'),\n",
    "    State('notch-freq', 'value'),\n",
    "    State('notch-enable', 'value'),\n",
    "    State('wavelet-enable', 'value'),\n",
    "    State('Highpass-enable', 'value'),\n",
    "    State(\"fmax\", \"value\"),\n",
    "    State(\"imu_on\", \"value\"), State(\"win_sec\", \"value\"), State(\"hop_sec\", \"value\"),\n",
    "    State(\"anc_on\", \"value\"), State(\"anc_mu\", \"value\"), State(\"anc_pad\", \"value\"),\n",
    "    State(\"aboy_on\", \"value\"), State(\"aboy_p\", \"value\"), State(\"aboy_win\", \"value\")\n",
    ")\n",
    "def analyze_file(_, \n",
    "                 folder, \n",
    "                 filename, \n",
    "                 folder_bias, \n",
    "                 filename_bias, \n",
    "                 ir_col, \n",
    "                 red_col, \n",
    "                 bp_order, \n",
    "                 bp_lowcut,\n",
    "                 bp_highcut, \n",
    "                 wl_level, \n",
    "                 hp_cutoff, \n",
    "                 notch_freq, \n",
    "                 notch_en, \n",
    "                 wavelet_en, \n",
    "                 highpass_en,\n",
    "                 fmax,            \n",
    "                 imu_on, win_sec, hop_sec,\n",
    "                 anc_on, anc_mu, anc_pad,\n",
    "                 aboy_on, aboy_p, aboy_win\n",
    "                 ):\n",
    "    \n",
    "    def empty_fig(title):\n",
    "        return go.Figure(layout=go.Layout(title=title, height=300, margin=dict(l=40, r=20, t=40, b=40)))\n",
    "\n",
    "    #---------------------------FFT------------------------------------------------------\n",
    "    def spectrum(sig, f_max):\n",
    "        \"\"\"for freq domain plot\"\"\"\n",
    "        n = len(sig)\n",
    "        freqs = np.fft.rfftfreq(n, 1/FS)     # 0 → Nyquist\n",
    "        mag   = np.abs(np.fft.rfft(sig)) / n \n",
    "        mask  = (freqs <= f_max) & (freqs > 0.01)               # visible fre\n",
    "        #print(len(freqs[mask]), len(mag[mask]))\n",
    "        #print(freqs[mask], mag[mask])\n",
    "        return freqs[mask], mag[mask]\n",
    "\n",
    "    \"\"\"Core logic: load CSV, filter signals, detect peaks, compute metrics, visualize.\"\"\"\n",
    "    if not filename: return dash.no_update\n",
    "    if not filename_bias: return dash.no_update\n",
    "    # Load selected CSV file\n",
    "    df = pd.read_csv(os.path.join(folder, filename))\n",
    "    df_bias = pd.read_csv(os.path.join(folder_bias, filename_bias))\n",
    "    # Show first three rows for preview\n",
    "    preview = DataTable(data=df.head(3).to_dict(\"records\"), columns=[{\"name\": i, \"id\": i} for i in df.columns])\n",
    "    preview_bias = DataTable(data=df_bias.head(3).to_dict(\"records\"), columns=[{\"name\": i, \"id\": i} for i in df.columns])\n",
    "    # Validate column names\n",
    "    if ir_col not in df.columns or red_col not in df.columns:\n",
    "        err = html.Div(\"❌ Column names incorrect\")\n",
    "        return preview, err, *[empty_fig(\"\") for _ in range(13)]\n",
    "\n",
    "    # Extract IR and RED columns\n",
    "    ir_raw, red_raw = df[ir_col].values, df[red_col].values\n",
    "    time = df['Time'].values if 'Time' in df else np.arange(len(ir_raw)) / FS\n",
    "    #print(time)\n",
    "    #print(len(time))\n",
    "    #print(len(ir_raw)/FS)\n",
    "    # process IMU bias\n",
    "    acc_b, gyro_b, roll0, pitch0, qual = estimate_bias_from_static(df_bias)\n",
    "    print(\"acc_bias (m/s^2):\", acc_b)\n",
    "    print(\"gyro_bias (rad/s):\", gyro_b)\n",
    "    print(\"init roll/pitch (rad):\", roll0, pitch0)\n",
    "    print(\"quality:\", qual)\n",
    "    # extract acc (N，3) m/s2 and gyro (N, 3) \n",
    "    #acc_raw = df[['AX', 'AY', 'AZ']].to_numpy(dtype=float) * G        # g → m/s²\n",
    "    #gyro_raw = df[['GX', 'GY', 'GZ']].to_numpy(dtype=float)            # °/s\n",
    "\n",
    "    #imu_output = imu_preprocess_with_kf(df, df_bias, fs=FS, acc_fc=20, gyro_fc=40, static_idx=None)\n",
    "    \"\"\"\n",
    "    acc_raw = df[['AX','AY','AZ']].to_numpy(float) * G\n",
    "    gyr_raw = np.deg2rad(df[['GX','GY','GZ']].to_numpy(float))\n",
    "\n",
    "    acc_b0, gyr_b0, roll0, pitch0, q = estimate_bias_from_static(df_bias)\n",
    "\n",
    "    acc_bias_corr = acc_raw - acc_b0\n",
    "    gyr_bias_corr = gyr_raw - gyr_b0\n",
    "\n",
    "    acc_f = lp(acc_bias_corr, 20, fs=FS, order=4, axis=0)\n",
    "    gyr_f = lp(gyr_bias_corr, 40, fs=FS, order=4, axis=0)\n",
    "\n",
    "    #init = dict(roll0=roll0, pitch0=pitch0, bg0=np.zeros(3))\n",
    "    roll, pitch, bg = ekf_attitude_rp(gyr_f, acc_f, fs=FS, init=None)\n",
    "\n",
    "    g_body = gravity_from_rp(roll, pitch)\n",
    "    a_dyn  = acc_f - g_body\n",
    "    print(a_dyn)\n",
    "    acc_mag  = np.linalg.norm(a_dyn, axis=1)\n",
    "    gyro_mag = np.linalg.norm(gyr_f, axis=1)\n",
    "    jerk     = np.diff(a_dyn, axis=0, prepend=a_dyn[:1]) * FS\n",
    "    jerk_mag = np.linalg.norm(jerk, axis=1)\n",
    "    \"\"\"\n",
    "\n",
    "        # ---- IMU classification ----\n",
    "    imu_res = None\n",
    "    if imu_on:\n",
    "        try:\n",
    "            imu_cols = None         # dict(ax='AX',ay='AY',az='AZ',gx='GX',gy='GY',gz='GZ')\n",
    "            imu_res = classify_motion_from_df(df, FS, cols=imu_cols, win_sec=win_sec, hop_sec=hop_sec)\n",
    "        except Exception:\n",
    "            imu_res = None\n",
    "            \n",
    "    acc_mag  = imu_res[\"acc_mag\"]\n",
    "    gyro_mag = imu_res[\"gyro_mag\"]\n",
    "    jerk_mag = imu_res[\"jerk_mag\"]        \n",
    "\n",
    "    # ---- ANC ----\n",
    "    anc_info = None\n",
    "    if anc_on and imu_res is not None:\n",
    "        ppg_raw = (ir_raw + red_raw) / 2.0\n",
    "        #notch_hz = nf if n_on else None\n",
    "        anc_info = hr_from_anc_pipeline(ppg_raw, imu_res, fs=FS,\n",
    "                                        hp_cut=hp_cutoff, notch_hz=None,\n",
    "                                        anc_mu=float(anc_mu), gate_pad=float(anc_pad),\n",
    "                                        bp_lo=0.5, bp_hi=8.0,\n",
    "                                        min_bpm=MIN_BPM, max_bpm=MAX_BPM)\n",
    "\n",
    "\n",
    "    #if n_on: y_min = notch_filter(y_min, nf)\n",
    "    # try raw peaks\n",
    "    #print(len(detect_common_peaks(ir_raw, red_raw)))\n",
    "    \n",
    "    # Apply high-pass filter\n",
    "    if highpass_en:\n",
    "        ir = highpass_filter(ir_raw, hp_cutoff)\n",
    "        red = highpass_filter(red_raw, hp_cutoff)\n",
    "    else: \n",
    "        ir = ir_raw\n",
    "        red = red_raw\n",
    "\n",
    "    # Apply band-pass filter\n",
    "    ir = bandpass_filter(ir, lowcut=bp_lowcut, highcut=bp_highcut, order=bp_order)\n",
    "    #ir = bandpass_filter(ir, lowcut=0.5, highcut=5, order=4)\n",
    "    red = bandpass_filter(red, lowcut=bp_lowcut, highcut=bp_highcut, order=bp_order)\n",
    "    #red = bandpass_filter(red, lowcut=0.5, highcut=5, order=4)\n",
    "\n",
    "\n",
    "    \n",
    "    # Optional: apply notch filter\n",
    "    #print(\"notch:\",notch_en)\n",
    "    if notch_en:\n",
    "        ir = notch_filter(ir, notch_freq)\n",
    "        red = notch_filter(red, notch_freq)\n",
    "    # Optional: apply smoothing denoising\n",
    "    if wavelet_en:\n",
    "        ir = wavelet_denoise(ir, level=wl_level)\n",
    "        red = wavelet_denoise(red, level=wl_level)\n",
    "\n",
    "    # Combine IR and RED signals\n",
    "    combined_raw = (ir_raw + red_raw) /2\n",
    "    combined = (ir + red) / 2\n",
    "\n",
    "        # ---- Aboy++ ----\n",
    "    aboy_info_raw = None\n",
    "    aboy_info_ir = None\n",
    "    if aboy_on:\n",
    "        #ppg_raw = (ir_raw + red_raw) / 2.0\n",
    "        #notch_hz = nf if n_on else None\n",
    "        \"\"\"\n",
    "        aboy_info_raw = aboypp_peak_hr(ir_raw, fs=FS, window_sec=float(aboy_win),\n",
    "                                   hp_cut=hp_cutoff, notch_hz=None,\n",
    "                                   init_HRi=0.0, amp_percentile=int(aboy_p),\n",
    "                                   low_cut=0.5, hi_cap=8.0,\n",
    "                                   min_bpm=MIN_BPM, max_bpm=MAX_BPM)\n",
    "        aboy_info_ir = aboypp_peak_hr(ir, fs=FS, window_sec=float(aboy_win),\n",
    "                            hp_cut=hp_cutoff, notch_hz=None,\n",
    "                            init_HRi=0.0, amp_percentile=int(aboy_p),\n",
    "                            low_cut=0.5, hi_cap=8.0,\n",
    "                            min_bpm=MIN_BPM, max_bpm=MAX_BPM)\n",
    "        \"\"\"\n",
    "        aboy_info_raw = aboypp_peak_hr_windowed(combined_raw, fs=FS, window_sec=float(aboy_win), hop_sec=2.0,\n",
    "                                                commit_tail_sec=4.0,\n",
    "                                                init_HRi=0.0, ema_alpha=0.3,\n",
    "                                                hp_cut=0.5, notch_hz=None, amp_percentile=65,\n",
    "                                                low_cut=0.5, hi_cap=8.0,\n",
    "                                                min_bpm=40, max_bpm=180\n",
    "                                            )\n",
    "        aboy_info_ir = aboypp_peak_hr_windowed(combined, fs=FS, window_sec=float(aboy_win), hop_sec=2.0,\n",
    "                                                commit_tail_sec=4.0,\n",
    "                                                init_HRi=0.0, ema_alpha=0.3,\n",
    "                                                hp_cut=0.5, notch_hz=None, amp_percentile=65,\n",
    "                                                low_cut=0.5, hi_cap=8.0,\n",
    "                                                min_bpm=40, max_bpm=180\n",
    "                                            )\n",
    "    # Detect common peaks\n",
    "    peaks_raw = detect_common_peaks(ir_raw, red_raw)\n",
    "    peaks = detect_common_peaks(ir, red)\n",
    "    print(\"peaks_raw:\", len(peaks))\n",
    "    # Estimate metrics\n",
    "    hr_clean, rr_clean, clean_peaks = caculate_clean_peaks(peaks, FS)\n",
    "    hrv = calculate_hrv(rr_clean)\n",
    "    print(\"clean peaks:\", len(clean_peaks))\n",
    "    print(\"Peaks by Aboy by ir:\",len(aboy_info_ir['peaks_global']))\n",
    "    print(\"Peaks by Aboy by raw:\",len(aboy_info_raw['peaks_global']))\n",
    "    print(\"HR by clean peaks:\", len(clean_peaks)*FS/len(ir_raw)*60)\n",
    "    #hrv = calculate_hrv(rr)\n",
    "    spo2 = estimate_spo2(ir, red, clean_peaks)\n",
    "    spo2_old = estimate_spo2_old(ir, red)\n",
    " \n",
    "\n",
    "    # Format results table\n",
    "\n",
    "    table1 = DataTable(\n",
    "        columns=[\n",
    "            {\"name\": \"Heart Rate (BPM)\", \"id\": \"hr\", \"type\": \"numeric\", \"format\": Format(precision=3)},\n",
    "            {\"name\": \"HRV (ms)\", \"id\": \"hrv\", \"type\": \"numeric\", \"format\": Format(precision=3)},\n",
    "            {\"name\": \"SpO₂ (%)\", \"id\": \"spo2\",\"type\": \"numeric\", \"format\": Format(precision=3)},\n",
    "            {\"name\": \"acc_bias (m/s²)\", \"id\": \"accb\", \"presentation\": \"markdown\"},\n",
    "            {\"name\": \"gyro_bias (rad/s)\", \"id\": \"gyrob\", \"presentation\": \"markdown\"},\n",
    "            {\"name\": \"init roll/pitch (rad)\", \"id\": \"initrp\", \"presentation\": \"markdown\"},\n",
    "        ],\n",
    "        data=[{\n",
    "            \"hr\": float(hr_clean), \n",
    "            \"hrv\": float(hrv), \n",
    "            \"spo2\": float(spo2),\n",
    "            \"accb\":  \"\\n\".join(f\"{float(x):.3f}\" for x in acc_b),\n",
    "            \"gyrob\": \"\\n\".join(f\"{float(x):.3f}\" for x in gyro_b),\n",
    "            \"initrp\": \"\\n\".join(f\"{float(x):.3f}\" for x in (roll0, pitch0)),\n",
    "        }],\n",
    "        style_cell={\"whiteSpace\": \"pre-line\"},  # 让换行可见\n",
    "    )\n",
    "\n",
    "    # 从 aboy_info_ir 构建 PPI 并生成对照表行（严格模式：若失败会直接抛异常）\n",
    "    ppi_ms, hrv_rows = hrv_compare_from_aboy_ir(\n",
    "        aboy_info_ir=aboy_info_ir,\n",
    "        fs_ppg=FS,                   # 你的 PPG 采样率变量\n",
    "        peaks_are_indices=True,          # 如果 peaks 已是秒，则设为 False\n",
    "        ppi_min_ms=300.0,\n",
    "        ppi_max_ms=2000.0,\n",
    "        deduplicate_ms=None,\n",
    "            # 两包各自预处理的对齐参数（可按数据质控调整）\n",
    "        preprocess = False,\n",
    "        hrv_apply_quotient=False,\n",
    "        hrv_threshold_strength=\"medium\",\n",
    "        hrv_local_median_size=5,\n",
    "        hrva_ectopic_method=\"malik\",\n",
    "        hrva_interpolation_method=\"linear\",\n",
    "        )\n",
    "\n",
    "    # Dash 表格组件（你可以直接放入现有 layout 或作为回调输出）\n",
    "    hrv_table = build_hrv_compare_table(hrv_rows)\n",
    "    # Create plotly figure\n",
    "    # combined filtered ppg time domain\n",
    "    fig_comb_time = go.Figure()\n",
    "    if len(aboy_info_ir['peaks_global']):\n",
    "        idx = aboy_info_ir['peaks_global']\n",
    "        fig_comb_time.add_trace(go.Scatter(x=time[idx], y=combined[idx], mode=\"markers\", name=\"Aboy++ peaks\", marker=dict(color='black', symbol = \"x\")))\n",
    "    fig_comb_time.add_trace(go.Scatter(x=time, y=combined, name='Combined PPG', line=dict(color='purple')))\n",
    "    fig_comb_time.add_trace(go.Scatter(x=time[peaks], y=combined[peaks], mode='markers', name='Peaks', marker=dict(color='red')))\n",
    "    fig_comb_time.update_layout(title='PPG Signal (Interactive)', xaxis_title='Time (s)', yaxis_title='Amplitude', height=600)\n",
    "\n",
    "    # zoomed filterde ppg 135-150s time domain\n",
    "    fig_zm_time = go.Figure()\n",
    "    z0 = int(len(ir_raw)/FS*0.7)\n",
    "    z1 = z0 + 10\n",
    "    mask = (time >= z0) & (time <= z1)\n",
    "    fig_zm_time.add_trace(go.Scatter(x=time[mask], y=combined[mask], name=\"Zoomed\", line=dict(color=\"purple\")))\n",
    "    fig_zm_time.update_layout(title=f\"Zoomed PPG ({z0}-{z1}s)\", xaxis_title=\"Time (s)\", yaxis_title=\"Amplitude\")\n",
    "\n",
    "    # aboy HR plot\n",
    "    fig_aboy_hr = go.Figure()\n",
    "    fig_aboy_hr = build_aboypp_windowed_sync_figure(\n",
    "                                                        ppg_raw, FS, aboy_info_ir,\n",
    "                                                        window_sec=10.0, hop_sec=2.0,\n",
    "                                                        height=880, show_commit_band=True, show_hr_points=True\n",
    "                                                    )\n",
    "    #fig_aboy_hr.update_layout(title=f\"Aboy++ HR Plot\", xaxis_title=\"Time (s)\", yaxis_title=\"BPM\")\n",
    "    # filtered IR ppg time domain\n",
    "    fig_IR_time = go.Figure()\n",
    "    #fig_IR_time.add_trace(go.Scatter(x=time, y=ir_raw, name=\"IR Raw\", line=dict(color=\"gray\", width=1), opacity=0.3))\n",
    "    fig_IR_time.add_trace(go.Scatter(x=time, y=ir_raw, name=\"IR Raw\", line=dict(color=\"blue\")))\n",
    "    if len(aboy_info_raw['peaks_global']):\n",
    "        idx = aboy_info_raw['peaks_global']\n",
    "        fig_IR_time.add_trace(go.Scatter(x=time[idx], y=ir_raw[idx], mode=\"markers\", name=\"Aboy++ peaks\", marker=dict(color='black', symbol = \"x\")))\n",
    "    #fig_IR_time.add_trace(go.Scatter(x=time[peaks_raw], y=ir_raw[peaks_raw], mode=\"markers\", name=\"Detected Peaks\", marker=dict(color=\"black\", symbol=\"x\")))\n",
    "    fig_IR_time.add_trace(go.Scatter(x=time[clean_peaks], y=ir_raw[clean_peaks], mode=\"markers\", name=\"Cleaned Peaks\", marker=dict(color=\"red\")))\n",
    "    fig_IR_time.update_layout(title=\"IR Signal\", xaxis_title=\"Time (s)\", yaxis_title=\"Amplitude\")\n",
    "\n",
    "    #filtered Red ppg time domain\n",
    "    fig_red_time = go.Figure()\n",
    "    #fig_red_time.add_trace(go.Scatter(x=time, y=red_raw, name=\"RED Raw\", line=dict(color=\"lightcoral\", width=1), opacity=0.3))\n",
    "    fig_red_time.add_trace(go.Scatter(x=time, y=red_raw, name=\"RED Filtered\", line=dict(color=\"red\")))\n",
    "    fig_red_time.update_layout(title=\"RED Signal\", xaxis_title=\"Time (s)\", yaxis_title=\"Amplitude\")\n",
    "    \n",
    "    #combined filtered ppg FFT\n",
    "    fig_comb_fft = go.Figure()\n",
    "    f_comb, m_comb = spectrum(combined, fmax)\n",
    "    fig_comb_fft.add_trace(go.Scatter(x=f_comb, y=m_comb, name=\"Combined FFT\", line=dict(color=\"purple\")))\n",
    "    fig_comb_fft.update_layout(title=\"Combined FFT\", xaxis_title=\"Frequency\", yaxis_title=\"Magnitude\")\n",
    "    fig_comb_fft.update_xaxes(title=\"Frequency (Hz)\")\n",
    "\n",
    "    fig_ir_fft = go.Figure()\n",
    "    #ir_raw = highpass_filter(ir_raw, hp_cutoff)\n",
    "    f_IR, m_IR = spectrum(ir_raw, fmax)\n",
    "    fig_ir_fft.add_trace(go.Scatter(x=f_IR, y=m_IR, name=\"IR Raw FFT\", line=dict(color=\"blue\")))\n",
    "    f_red, m_red = spectrum(red_raw, fmax)\n",
    "    fig_ir_fft.add_trace(go.Scatter(x=f_red, y=m_red, name=\"RED Raw FFT\", line=dict(color=\"red\")))\n",
    "    fig_ir_fft.update_layout(title=f\"Raw FFT 0.02-{fmax}Hz\", xaxis_title=\"Frequency\", yaxis_title=\"Magnitude\")\n",
    "    fig_ir_fft.update_xaxes(title=\"Frequency (Hz)\")\n",
    "\n",
    "    fig_red_fft = go.Figure()\n",
    "    #f_red, m_red = spectrum(red_raw, fmax)\n",
    "    fig_red_fft.add_trace(go.Scatter(x=f_red, y=m_red, name=\"RED Raw FFT\", line=dict(color=\"red\")))\n",
    "    fig_red_fft.update_layout(title=f\"Red Raw FFT 0.02-{fmax}Hz\", xaxis_title=\"Frequency\", yaxis_title=\"Magnitude\")\n",
    "    fig_red_fft.update_xaxes(title=\"Frequency (Hz)\")\n",
    "# ---------- Motion ---------- #\n",
    "    fig_gyro_jerk_time = go.Figure()\n",
    "    fig_gyro_jerk_time.add_trace(go.Scatter(x=time, y=acc_mag,  name='AccMag (m/s²)', line=dict(color=\"red\")))\n",
    "    fig_gyro_jerk_time.add_trace(go.Scatter(x=time, y=gyro_mag, name='GyroMag (°/s)', line=dict(color=\"blue\")))\n",
    "    #fig_gyro_jerk_time.add_trace(go.Scatter(x=time, y=jerk_mag, name='JerkMag', line=dict(color=\"yellow\")))\n",
    "    fig_gyro_jerk_time.update_layout(title='IMU Magnitude - Time Domain',\n",
    "                        xaxis_title='Time (s)', yaxis_title='Magnitude')\n",
    "\n",
    "    fig_acc_time = go.Figure()\n",
    "    fig_acc_time.add_trace(go.Scatter(x=time, y=acc_mag,  name='AccMag (m/s²)', line=dict(color=\"red\")))\n",
    "    fig_acc_time.update_layout(title='ACC Magnitude - Time Domain',\n",
    "                        xaxis_title='Time (s)', yaxis_title='Magnitude')\n",
    "\n",
    "    fig_gyro_jerk_FFT = go.Figure()\n",
    "    f_acc, m_acc = spectrum(acc_mag, fmax)\n",
    "    f_gyro, m_gyro = spectrum(gyro_mag, fmax)\n",
    "    f_jerk, m_jerk = spectrum(jerk_mag, fmax)\n",
    "    fig_gyro_jerk_FFT.add_trace(go.Scatter(x=f_acc,  y=m_acc,  name='AccMag FFT', line=dict(color=\"red\")))\n",
    "    fig_gyro_jerk_FFT.add_trace(go.Scatter(x=f_gyro, y=m_gyro, name='GyroMag FFT', line=dict(color=\"blue\")))\n",
    "    fig_gyro_jerk_FFT.add_trace(go.Scatter(x=f_jerk, y=m_jerk, name='JerkMag FFT', line=dict(color=\"yellow\")))\n",
    "    fig_gyro_jerk_FFT.update_layout(title=f'IMU Magnitude - Frequency Domain (0.01-{fmax} Hz)',\n",
    "                        xaxis_title='Frequency (Hz)', yaxis_title='Magnitude')\n",
    "    \n",
    "    fig_acc_FFT = go.Figure()\n",
    "    f_acc, m_acc = spectrum(acc_mag, fmax)\n",
    "    fig_acc_FFT.add_trace(go.Scatter(x=f_acc,  y=m_acc,  name='AccMag FFT', line=dict(color=\"red\")))\n",
    "    fig_acc_FFT.update_layout(title=f'ACC Magnitude - Frequency Domain (0.01-{fmax} Hz)',\n",
    "                        xaxis_title='Frequency (Hz)', yaxis_title='Magnitude')\n",
    "    \n",
    "    # IMU time & class (combined figure + labeled colors)\n",
    "    fig_imu_t = empty_fig(\"Motion-Class disabled\")\n",
    "    if imu_res is not None:\n",
    "        # Build discrete colorscale from LABEL_COLORS / MOTION_LABELS\n",
    "        try:\n",
    "            C = len(MOTION_LABELS)\n",
    "            colorscale = [[i/(C-1 if C>1 else 1), LABEL_COLORS[MOTION_LABELS[i]]] for i in range(C)]\n",
    "        except Exception:\n",
    "            # Fallback to Viridis if labels/color map not available\n",
    "            C = int(np.nanmax(imu_res['ids'])) + 1 if len(imu_res['ids']) else 1\n",
    "            colorscale = 'Viridis'\n",
    "        ids = imu_res['ids']\n",
    "        t_imu = imu_res['time']\n",
    "\n",
    "        # Combine time-series (AccMag, GyroMag) and class heatmap in one figure\n",
    "        fig_imu_t = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
    "                                  row_heights=[0.72, 0.28], vertical_spacing=0.02)\n",
    "        fig_imu_t.add_trace(go.Scatter(x=t_imu, y=imu_res['acc_mag'], name=\"AccMag (|a_dyn|)\"), row=1, col=1)\n",
    "        fig_imu_t.add_trace(go.Scatter(x=t_imu, y=imu_res['gyro_mag'], name=\"GyroMag (|ω|)\"), row=1, col=1)\n",
    "        fig_imu_t.add_trace(go.Scatter(x=t_imu, y=imu_res['jerk_mag'], name=\"JerkMag\"), row=1, col=1)\n",
    "\n",
    "        # Heatmap with labeled colorbar\n",
    "        # Heatmap WITHOUT gradient colorbar; we'll add a legend instead\n",
    "        heat = go.Heatmap(\n",
    "            z=ids[np.newaxis, :],\n",
    "            x=t_imu,\n",
    "            y=[\"Class\"],\n",
    "            colorscale=colorscale,\n",
    "            zmin=0,\n",
    "            zmax=(C-1),\n",
    "            showscale=False  # turn off gradient colorbar\n",
    "        )\n",
    "        fig_imu_t.add_trace(heat, row=2, col=1)\n",
    "\n",
    "        # Build a discrete legend: one legend-only scatter per motion class\n",
    "        if 'MOTION_LABELS' in globals():\n",
    "            for name in MOTION_LABELS:\n",
    "                fig_imu_t.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[t_imu[0]], y=[imu_res['acc_mag'][0]],  # dummy point\n",
    "                        mode='markers',\n",
    "                        marker=dict(color=LABEL_COLORS.get(name, '#999'), size=10),\n",
    "                        name=name,\n",
    "                        legendgroup='motion',\n",
    "                        showlegend=True,\n",
    "                        visible='legendonly'  # show only in legend\n",
    "                    ), row=1, col=1\n",
    "                )\n",
    "\n",
    "        fig_imu_t.update_yaxes(title_text=\"Magnitude\", row=1, col=1)\n",
    "        fig_imu_t.update_yaxes(showticklabels=False, row=2, col=1)\n",
    "        fig_imu_t.update_layout(\n",
    "            height=420,\n",
    "            margin=dict(l=40, r=20, t=40, b=40),\n",
    "           # legend=dict(orientation='r', yanchor='bottom', y=1.02, xanchor='left', x=0)\n",
    "        )\n",
    "        fig_imu_t.update_layout(title='IMU Magnitude & Motion class - Time Domain',\n",
    "                         yaxis_title='Magnitude')\n",
    "    \n",
    "    #fig_EMD_1\n",
    "    # ppg_raw: 1D array, FS: sampling rate\n",
    "    out_EMD = remove_ma_cemd_lms(\n",
    "    ppg_raw, fs=FS,\n",
    "    ce_pairs=6, ce_noise_ratio=0.2, ce_max_imfs=6,  # CEEMD 参数（可小步调）\n",
    "    lms_L=32, lms_mu=0.1, lms_leak=1e-4             # LMS 参数（稳定缺省）\n",
    ")\n",
    "\n",
    "    fig_EMD_1 = build_cemd_lms_figure(ppg_raw, FS, out_EMD, height=480)\n",
    "\n",
    "\n",
    "        \n",
    "        # ANC time & freq\n",
    "    fig_anc_t = empty_fig(\"ANC disabled or no IMU\")\n",
    "    fig_anc_f = empty_fig(\"ANC disabled or no IMU\")\n",
    "    if anc_info is not None:\n",
    "        fig_anc_t = go.Figure()\n",
    "        fig_anc_t.add_trace(go.Scatter(x=time, y=anc_info['y_min'], name=\"PPG raw\"))\n",
    "        fig_anc_t.add_trace(go.Scatter(x=time, y=anc_info['y_band'], name=\"PPG ANC-bandfilt\"))\n",
    "        fig_anc_t.add_trace(go.Scatter(x=time, y=anc_info['y_clean'], name=\"PPG ANC-clean\"))\n",
    "        pc = anc_info.get('peaks_clean', np.array([], int))\n",
    "        if len(pc):\n",
    "            fig_anc_t.add_trace(go.Scatter(x=time[pc], y=anc_info['y_clean'][pc], mode=\"markers\", name=\"ANC peaks\"))\n",
    "        fig_anc_t.update_layout(height=300, margin=dict(l=40, r=20, t=40, b=40))\n",
    "        fig_anc_t.update_layout(title='NLMS-Clean vs Raw- Time Domain',\n",
    "                         yaxis_title='Magnitude')\n",
    "        # spectra\n",
    "        f_clean, m_clean = spectrum(anc_info['y_band'], fmax)\n",
    "        f_comb, m_comb = spectrum(combined, fmax)\n",
    "        fig_anc_f.add_trace(go.Scatter(x=f_comb, y=m_comb, name=\"Combined FFT\", line=dict(color=\"blue\")))\n",
    "        fig_anc_f.add_trace(go.Scatter(x=f_clean, y=m_clean, name=\"Cleaned FFT\", line=dict(color=\"Red\")))\n",
    "        fig_anc_f.update_layout(title=\"Combined FFT vs Cleaned FFT\", xaxis_title=\"Frequency\", yaxis_title=\"Magnitude\")\n",
    "        fig_anc_f.update_xaxes(title=\"Frequency (Hz)\")\n",
    "            \n",
    "\n",
    "    print(\"END###########\")\n",
    "    \n",
    "    output = [preview_bias, \n",
    "              preview, table1,\n",
    "              hrv_table, \n",
    "              fig_comb_time,\n",
    "              fig_zm_time, \n",
    "              fig_aboy_hr,\n",
    "              fig_IR_time, \n",
    "              fig_red_time, \n",
    "              fig_comb_fft, \n",
    "              fig_ir_fft, \n",
    "              #fig_red_fft, \n",
    "              fig_gyro_jerk_time, \n",
    "              #fig_acc_time, \n",
    "              fig_gyro_jerk_FFT, \n",
    "              #fig_acc_FFT, \n",
    "              fig_imu_t, \n",
    "              fig_EMD_1,\n",
    "              fig_anc_t, #NLMS-Clean vs Raw- Time Domain\n",
    "              fig_anc_f   #\"Combined FFT vs Cleaned FFT\"\n",
    "              ]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ca077b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x77543dba0910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_bias (m/s^2): [ 1.71994663  0.1101592  -2.38784454]\n",
      "gyro_bias (rad/s): [ 0.03472235 -0.01407243  0.00374037]\n",
      "init roll/pitch (rad): 1.3448784590611949 -0.22451139953002514\n",
      "quality: {'acc_norm_error': 0.0, 'gyro_rms': [0.03904805083978658, 0.024212669438684487, 0.022071382114265573], 'window_len': 38000}\n",
      "peaks_raw: 336\n",
      "clean peaks: 334\n",
      "Peaks by Aboy by ir: 330\n",
      "Peaks by Aboy by raw: 330\n",
      "HR by clean peaks: 66.65391683227594\n",
      "Ratio_raw: 107.68640550356932 -235.39194747191056 170\n",
      "Ratio_filtered 1.4931440659625954 0.17148881021002566 134\n",
      "R_mean: 0.2857985747669062\n",
      "R_clean_mean: 0.8052805442575406\n",
      "ratio_old 0.9966347127689112\n",
      "0 outlier(s) have been deleted.\n",
      "7 ectopic beat(s) have been deleted with malik rule.\n",
      "END###########\n"
     ]
    }
   ],
   "source": [
    "# --- Run Dash App ---\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e528a062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n###Heart Rate####\\nfind peaks: NeuroKit/ Charlton \\n\\n\\n###spo2####\\nspo2 linear regression function need correct parameters\\n\\n\\n\\n###motion artifact cancelling with IMU sig###\\nacc: *g -> m /s2\\nrotate: degree/s \\n\\na_motion = a_meas - g - b_acc\\n\\nstatic bias\\nbandpass\\nextract motion features\\n\\nkalman filter\\nAttitude fusion: initial attitude\\nSeparate gravity vector\\n\\nLinear regression\\nnoise predict\\nAdaptive Noise Cancelling: LMS/RLS\\n\\n\\n####options#####\\nremove_large_spikes\\nget_prominence\\nsubtract_ac\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "###Heart Rate####\n",
    "find peaks: NeuroKit/ Charlton \n",
    "\n",
    "\n",
    "###spo2####\n",
    "spo2 linear regression function need correct parameters\n",
    "\n",
    "\n",
    "\n",
    "###motion artifact cancelling with IMU sig###\n",
    "acc: *g -> m /s2\n",
    "rotate: degree/s \n",
    "\n",
    "a_motion = a_meas - g - b_acc\n",
    "\n",
    "static bias\n",
    "bandpass\n",
    "extract motion features\n",
    "\n",
    "kalman filter\n",
    "Attitude fusion: initial attitude\n",
    "Separate gravity vector\n",
    "\n",
    "Linear regression\n",
    "noise predict\n",
    "Adaptive Noise Cancelling: LMS/RLS\n",
    "\n",
    "\n",
    "####options#####\n",
    "remove_large_spikes\n",
    "get_prominence\n",
    "subtract_ac\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a40a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ddff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
